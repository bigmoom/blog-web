<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="google-site-verification" content="_i0mgfxBy6QPgJZLx5NbYfLAp5i5xqHoSKIcpYOPHM0" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="_i0mgfxBy6QPgJZLx5NbYfLAp5i5xqHoSKIcpYOPHM0">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.caiwanghui.top","root":"/","scheme":"Mist","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="因为准备忙毕设的事情，就开始学习推荐系统的相关知识，但是一开始就看到item-based CF和SVD的时候，发现很多线性代数的知识都忘了，就准备开这篇来重新学习一下 线性代数   我主要以YouTube上 为程序员设计的线性代数课程 为资源展开学习（这个貌似是慕课网的资源） 后来发现B站也有。B站链接（好像没了）">
<meta property="og:type" content="article">
<meta property="og:title" content="线性代数相关知识">
<meta property="og:url" content="http://www.caiwanghui.top/2020/03/12/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/index.html">
<meta property="og:site_name" content="菜鸡肥肥的私人博客">
<meta property="og:description" content="因为准备忙毕设的事情，就开始学习推荐系统的相关知识，但是一开始就看到item-based CF和SVD的时候，发现很多线性代数的知识都忘了，就准备开这篇来重新学习一下 线性代数   我主要以YouTube上 为程序员设计的线性代数课程 为资源展开学习（这个貌似是慕课网的资源） 后来发现B站也有。B站链接（好像没了）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311205312.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311205811.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311211910.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311221759.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311223948.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311224902.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312151122.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312153308.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312153541.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312170024.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312195348.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312202913.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312203352.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312202606.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312213920.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312220714.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312222100.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312222504.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312225804.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313132144.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313171739.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313202840.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313215959.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313220027.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314110945.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314173253.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314194838.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314195947.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314200715.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314201839.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200319211345.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200319211450.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200319211617.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200320223104.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200321104427.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200321112913.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200321165419.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200322180416.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200323111657.png">
<meta property="og:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200324135225.png">
<meta property="article:published_time" content="2020-03-11T20:09:32.000Z">
<meta property="article:modified_time" content="2022-10-25T10:21:57.557Z">
<meta property="article:author" content="Wanghui Cai">
<meta property="article:tag" content="线性代数">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311205312.png">

<link rel="canonical" href="http://www.caiwanghui.top/2020/03/12/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>线性代数相关知识 | 菜鸡肥肥的私人博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">菜鸡肥肥的私人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.caiwanghui.top/2020/03/12/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Wanghui Cai">
      <meta itemprop="description" content="一些零零散散的学习总结">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="菜鸡肥肥的私人博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          线性代数相关知识
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-11 20:09:32" itemprop="dateCreated datePublished" datetime="2020-03-11T20:09:32Z">2020-03-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-10-25 10:21:57" itemprop="dateModified" datetime="2022-10-25T10:21:57Z">2022-10-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">基础知识</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>40k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>36 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>因为准备忙毕设的事情，就开始学习推荐系统的相关知识，但是一开始就看到<code>item-based CF</code>和<code>SVD</code>的时候，发现很多线性代数的知识都忘了，就准备开这篇来重新学习一下 <strong>线性代数</strong></p>
</blockquote>
<blockquote>
<p>我主要以<code>YouTube</code>上 <a href="https://www.youtube.com/playlist?list=PL0Kneloi6O0zyVKekh4faY6vun_jkDVko" target="_blank" rel="noopener">为程序员设计的线性代数课程</a> 为资源展开学习（这个貌似是慕课网的资源）</p>
<p>后来发现B站也有。<a href="https://www.bilibili.com/video/av94991431" target="_blank" rel="noopener">B站链接</a>（好像没了）</p>
</blockquote>
<a id="more"></a>

<h1 id="概论"><a href="#概论" class="headerlink" title="概论"></a>概论</h1><blockquote>
<p>真实世界是<strong>多维度</strong>的，因此传统的<strong>单变量</strong>不足以描述真实世界</p>
<p>而<strong>线性代数</strong>是研究<strong>一组数</strong>，即 <strong>向量</strong> ，这也就是我们为什么要学习<strong>线性代数</strong>。</p>
</blockquote>
<h1 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h1><blockquote>
<p>一组数的基本表示方法 –<strong>向量</strong>（<code>Vector</code>）</p>
<p><code>Vector</code>是线性代数研究的基本元素</p>
<p>有什么用？    最基本上的出发点：<strong>表方向</strong></p>
<p><strong>例</strong>：我走了5000米，单独这个数据<strong>5000米</strong>并没有在现实生活中表述清楚，这个时候就要引入<strong>向量</strong>这个概念来表示我往哪个方向走了5000米。</p>
</blockquote>
<p><img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311205312.png" alt=""></p>
<blockquote>
<p>为了研究方便，我们定义向量都从 <strong>原点</strong> 起始。</p>
<p>但是如果只是表示方向，最多三个维度就够了 –&gt; 引入更加抽象的：<strong>n维向量</strong></p>
<p>不同角度刻画一个事物，例如下图<strong>（120,3,2,2,666）</strong>五个维度来刻画一个屋子。</p>
</blockquote>
<p><img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311205811.png" alt=""></p>
<blockquote>
<p><strong>一个方向，就是一个点；空间中的一个点，可以看做从原点指向这个点的一个方向。</strong></p>
</blockquote>
<h2 id="行向量和列向量"><a href="#行向量和列向量" class="headerlink" title="行向量和列向量"></a>行向量和列向量</h2><p>行向量$\begin{pmatrix}<br>3 &amp; 4\<br>\end{pmatrix}$       列向量$\begin{pmatrix}<br>3\<br>4\<br>\end{pmatrix}$</p>
<blockquote>
<p>通常教材，论文，提到向量，都是指<strong>列向量</strong> </p>
</blockquote>
<h2 id="向量加法"><a href="#向量加法" class="headerlink" title="向量加法"></a>向量加法</h2><p>$$<br>\begin{pmatrix}<br>5\<br>2\<br>\end{pmatrix}<br>+<br>\begin{pmatrix}<br>2\<br>5\<br>\end{pmatrix}<br>= ?<br>$$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311211910.png" width="30%" height="30%">

<blockquote>
<p>相当于从<strong>（0,0）</strong>走到<strong>（5,2）</strong>，在走<strong>（2,5）</strong>方向，走到<strong>（7,7）</strong></p>
<p>所以向量相加就是直接<strong>分别相加</strong></p>
</blockquote>
<h2 id="向量数量乘法"><a href="#向量数量乘法" class="headerlink" title="向量数量乘法"></a>向量数量乘法</h2><p>$$<br>2 *<br>\begin{pmatrix}<br>5\<br>2\<br>\end{pmatrix}=<br>\begin{pmatrix}<br>5<em>2\<br>2</em>2\<br>\end{pmatrix}<br>$$</p>
<blockquote>
<p>乘法本义便是加法的累加</p>
</blockquote>
<h2 id="向量运算的基本性质"><a href="#向量运算的基本性质" class="headerlink" title="向量运算的基本性质"></a>向量运算的基本性质</h2><blockquote>
<p>满足<strong>分配率，结合律</strong></p>
</blockquote>
<h2 id="零向量"><a href="#零向量" class="headerlink" title="零向量"></a>零向量</h2><p>对于任意一个向量$\vec{u}$,都存在一个向量$O$，满足：$\vec{u}+O=\vec{u}$</p>
<blockquote>
<p>我们称这个向量，为<strong>零向量</strong>（零向量$O$<strong>没有箭头</strong>）</p>
</blockquote>
<h2 id="向量的长度"><a href="#向量的长度" class="headerlink" title="向量的长度"></a>向量的长度</h2><p>$$<br>\vec{u}=\begin{pmatrix}<br>3 &amp; 4\<br>\end{pmatrix},\parallel\vec{u}\parallel=\sqrt{3^2+4^2}=5<br>$$</p>
<blockquote>
<p>（双竖线其实是表示<strong>二范数</strong>，<strong>欧拉距离</strong>）</p>
</blockquote>
<h2 id="单位向量"><a href="#单位向量" class="headerlink" title="单位向量"></a>单位向量</h2><p>$$<br>\vec{u}=(u_1,u_2,…,u_n)^T \<br>\hat{u}=\frac{1}{\parallel\vec{u}\parallel}\cdot\vec{u}=(\frac{u_1}{\parallel\vec{u}\parallel},\frac{u_2}{\parallel\vec{u}\parallel},…,\frac{u_n}{\parallel\vec{u}\parallel}) \<br>\parallel\hat{u}\parallel=1 \ \ \ \ 只表示方向<br>$$</p>
<blockquote>
<p> 根据$\vec{u}$求出$\hat{u}$的过程：<strong>归一化，规范化（normalize）</strong></p>
<p> 只有 <strong>0,1</strong> 组成的单位向量：<strong>标准单位向量 Standard Unit Vector</strong></p>
</blockquote>
<h2 id="向量的点乘"><a href="#向量的点乘" class="headerlink" title="向量的点乘"></a>向量的点乘</h2><blockquote>
<p> <strong>$\vec{u}\cdot\vec{v}=?$</strong></p>
</blockquote>
<p>$$<br>\vec{u}\cdot\vec{v}=\begin{pmatrix}u_1\\u_2\...\\u_n\\\end{pmatrix}\cdot\begin{pmatrix}v_1\\v_2\...\\v_n\\\end{pmatrix}=\sum_{i=0}^n\begin{pmatrix}u_1\cdot v_1\\u_2\cdot v_2\...\\u_n\cdot v_1\\\end{pmatrix}<br>$$</p>
<blockquote>
<p>两个向量<strong>点乘/内积</strong>，结果为一个<strong>标量</strong>，即为一个数</p>
</blockquote>
<p>$$<br>\vec{u}\cdot\vec{v}=\parallel\vec{u}\parallel\cdot\parallel\vec{v}\parallel\cos(\Theta)<br>$$</p>
<blockquote>
<p>以二维空间为例证明</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311221759.png" style="zoom:67%;" /> 

<p>通过余弦定理来证明（余弦定理的证明很简单，算就完了，这里就不写了）</p>
</blockquote>
<p>$$<br>\begin{align}\parallel \vec{u}-\vec{v} \parallel^2&amp;=\parallel\vec{u}\parallel^2+\parallel\vec{v}\parallel^2-2\cdot\parallel\vec{u}\parallel\cdot\parallel\vec{v}\parallel\cos(\Theta)\\\parallel\vec{u}\parallel\cdot\parallel\vec{v}\parallel\cos(\Theta)&amp;=\frac{1}{2}(\parallel\vec{u}\parallel^2+\parallel\vec{v}\parallel^2-\parallel \vec{u}-\vec{v} \parallel^2)\<br>&amp;= \frac{1}{2}(x_1^2+y_1^2+x_2^2+y_2^2-(x_1-x_2)^2-(y_1-y_2)^2)\<br>&amp;=\frac{1}{2}(x_1^2+y_1^2+x_2^2+y_2^2-x_1^2-x_2^2-y_1^2-y_2^2+2x_1x_2+2y_1y_2)\<br>&amp;=x_1x_2+y_1y_2<br>\end{align}<br>$$</p>
<blockquote>
<p><strong>两个向量的点乘就是两个向量投影到同一方向后的长度的积</strong></p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311223948.png" style="zoom:67%;" />

<h2 id="向量的点乘的应用"><a href="#向量的点乘的应用" class="headerlink" title="向量的点乘的应用"></a>向量的点乘的应用</h2><p>$$<br>\vec{u}\cdot\vec{v}=\parallel\vec{u}\parallel\cdot\parallel\vec{v}\parallel\cos(\Theta)\<br>cos(\Theta)=\frac{\vec{u}\cdot\vec{v}}{\parallel\vec{u}\parallel\cdot\parallel\vec{v}\parallel}<br>$$</p>
<blockquote>
<p>如果 $\Theta=90\circ$,$\vec{u}\cdot\vec{v}=0$</p>
<p>如果$\vec{u}\cdot\vec{v}=0$，两个向量<strong>垂直</strong>；</p>
<p>如果$\vec{u}\cdot\vec{v}&gt;0$,两个向量夹角为<strong>锐角</strong>；</p>
<p>如果$\vec{u}\cdot\vec{v}&lt;0$,两个向量夹角为<strong>钝角</strong>。</p>
</blockquote>
<blockquote>
<p>判断两个向量的相似程度（<strong>推荐系统</strong>）</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200311224902.png" style="zoom:60%;" />
</blockquote>
<h1 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h1><h2 id="什么是矩阵"><a href="#什么是矩阵" class="headerlink" title="什么是矩阵"></a>什么是矩阵</h2><blockquote>
<p>向量是对数的拓展，一个向量表示一组数</p>
<p>矩阵是对向量的拓展，一个矩阵表示一组向量</p>
</blockquote>
<p>$$<br>\begin{pmatrix}1&amp;2&amp;3&amp;4\\5&amp;6&amp;7&amp;8\\9&amp;10&amp;11&amp;12\\13&amp;14&amp;15&amp;16\end{pmatrix}        行数=列数-&gt; 方阵<br>$$</p>
<blockquote>
<p> $a_{ij}$表第<code>i</code>行第<code>j</code>列</p>
</blockquote>
<h2 id="矩阵基本运算"><a href="#矩阵基本运算" class="headerlink" title="矩阵基本运算"></a>矩阵基本运算</h2><p>$$<br>A=\begin{pmatrix}a_{11}&amp;a_{12}&amp;…&amp;a_{1c}\\a_{21}&amp;a_{22}&amp;…&amp;a_{2c}\...&amp;…&amp;…&amp;…\\a_{r1}&amp;a_{r2}&amp;…&amp;a_{rc}\end{pmatrix} \ \ B=\begin{pmatrix}b_{11}&amp;b_{12}&amp;…&amp;b_{1c}\\b_{21}&amp;b_{22}&amp;…&amp;b_{2c}\...&amp;…&amp;…&amp;…\\b_{r1}&amp;b_{r2}&amp;…&amp;b_{rc}\end{pmatrix}\<br> \<br>A+B=\begin{pmatrix}a_{11}+b_{11}&amp;a_{12}+b_{12}&amp;…&amp;a_{1c}+b_{1c}\\a_{21}+b_{21}&amp;a_{22}+b_{22}&amp;…&amp;a_{2c}+b_{2c}\...&amp;…&amp;…&amp;…\\a_{r1}+b_{r1}&amp;a_{r2}+b_{r2}&amp;…&amp;a_{rc}+b_{rc}\end{pmatrix}<br>$$</p>
<h2 id="矩阵看做系统"><a href="#矩阵看做系统" class="headerlink" title="矩阵看做系统"></a>矩阵看做系统</h2><blockquote>
<p>就拿经济系统举例 </p>
<p>我们设对 <strong>IT</strong>，<strong>电子</strong>，<strong>矿产</strong>，<strong>房产</strong>的投入为  $x_{it}\ \ x_e\ \ x_m\ \ x_h$</p>
</blockquote>
<p>$$<br>\begin{align}x_{it} &amp; =100+0.2x_e+0.1x_m+0.5x_h\\x_e &amp;= 50+0.5x_{it}+0.2x_m+0.1x_h\\x_m &amp;=20+0.4x_e +0.3x_h\\x_h &amp;=666+0.2x_{it}\end{align}-&gt;\begin{cases}x_{it}-0.2x_e+0.1x_m+0.5x_h &amp;=100\-0.5x_{it}-x_e+0.2x_m+0.1x_h&amp;=50\-0.4x_e-x_m+0.3x_h&amp;=20\-0.2x_{it}+x_h&amp;=666\end{cases}<br>$$</p>
<blockquote>
<p>对于 <strong>IT行业</strong>，我们至少需要投入原始的100亿，但是100亿是不够的，我们在其他的领域，需要 <strong>It 行业</strong>的支撑，换句话说，其他行业的发展，<strong>IT行业</strong>投入的比重一定要达到一定比例，例如<strong>电子行业</strong>需要将<strong>20%</strong>的投入投入于<strong>IT行业</strong>来支撑本行业的发展，依次类推，得到IT行业的总投入金额。</p>
<p>就这样，我们最后通过每个行业的一个制约式，也就形成了这个小的经济系统。</p>
</blockquote>
<p>$$<br>\begin{pmatrix}1 &amp; -0.2 &amp; 0.1 &amp; 0.5\-0.5 &amp; -1 &amp; 0.2 &amp; 0.1\\0 &amp; -0.4 &amp; -1 &amp; 0.3\-0.2 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix}\begin{pmatrix}x_{it}\\x_e\\x_m\\x_h\\\end{pmatrix}\ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \begin{pmatrix}100\\50\\20\\666\\\end{pmatrix}<br>$$</p>
<blockquote>
<p>把左侧矩阵记为A，变量列向量$\vec{x}$，结果列向量$\vec{b}$，即可得：</p>
</blockquote>
<p>$$<br>A\cdot\vec{x}=\vec{b}<br>$$</p>
<blockquote>
<p>这也就是矩阵与向量的乘法，即矩阵的每个行向量乘以列向量，结果是一个列向量。</p>
<p>如下所示，其中$\vec{r_m}$是矩阵每一行的行向量,$\vec{u}$为列向量</p>
</blockquote>
<p>$$<br>\begin{pmatrix}–\vec{r_1}–\--\vec{r_2}–\...\--\vec{r_m}–\\\end{pmatrix}\cdot\vec{u}=\begin{pmatrix}\vec{r_1}\cdot\vec{u}\\\vec{r_2}\cdot\vec{u}\...\\\vec{r_m}\cdot\vec{u}\\\end{pmatrix}<br>$$</p>
<blockquote>
<p>矩阵实际上是将一个向量转换为另一个向量，也就可以把矩阵理解成<strong>向量的函数</strong></p>
<p>这里以矩阵在图形变换中的应用为例:</p>
<p>我有一个坐标$\begin{pmatrix}x\\y\end{pmatrix}$，想要把横坐标扩大1.5倍，纵坐标扩大2倍，即得到$\begin{pmatrix}1.5x\\2y\end{pmatrix}$</p>
</blockquote>
<p>$$<br>\begin{pmatrix}a &amp; b\\c &amp; d\\\end{pmatrix}\cdot\begin{pmatrix}x\\y\end{pmatrix}=\begin{pmatrix}ax+by\\cx+dy\\\end{pmatrix}<br>$$</p>
<blockquote>
<p>很容易得到变化矩阵为$T=\begin{pmatrix}1.5&amp;0\\0&amp;2\end{pmatrix}$</p>
</blockquote>
<h2 id="矩阵和矩阵的乘法"><a href="#矩阵和矩阵的乘法" class="headerlink" title="矩阵和矩阵的乘法"></a>矩阵和矩阵的乘法</h2><blockquote>
<p>继续以上面的图形变换应用为例</p>
<p>我平面上有个图形，我想把每个点的坐标都做这样的变化</p>
</blockquote>
<p>$$<br>图形坐标矩阵P=\begin{pmatrix}0&amp;4&amp;5\\0&amp;0&amp;3\end{pmatrix}\\T\cdot P=\begin{pmatrix}1.5&amp;0\\0&amp;2\end{pmatrix}\cdot \begin{pmatrix}0&amp;4&amp;5\\0&amp;0&amp;3\end{pmatrix}=\begin{pmatrix}0&amp;6&amp;7.5\\0&amp;0&amp;6\end{pmatrix}<br>$$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312151122.png" style="zoom:50%;" />

<blockquote>
<p>通式</p>
</blockquote>
<p>$$<br>A\cdot B=A\cdot \begin{pmatrix}| &amp; | &amp; &amp;| \\\vec{c_1} &amp;\vec{c_2}&amp;…&amp;\vec{c_n}\| &amp; | &amp; &amp;| \\\end{pmatrix} =\begin{pmatrix}- &amp; \vec{r_1} &amp;-\- &amp; \vec{r_2} &amp;-\...\- &amp; \vec{r_m} &amp;-\\\end{pmatrix}\cdot \begin{pmatrix}| &amp; | &amp; &amp;| \\\vec{c_1} &amp;\vec{c_2}&amp;…&amp;\vec{c_n}\| &amp; | &amp; &amp;| \\\end{pmatrix}\=\begin{pmatrix}\vec{r_1}\cdot \vec{c_1} &amp; \vec{r_1}\cdot \vec{c_2}&amp;…&amp;\vec{r_1}\cdot \vec{c_n}\\\vec{r_2}\cdot \vec{c_1} &amp; \vec{r_2}\cdot \vec{c_2}&amp;…&amp;\vec{r_2}\cdot \vec{c_n}\...\\\vec{r_m}\cdot \vec{c_1} &amp; \vec{r_m}\cdot \vec{c_2}&amp;…&amp;\vec{r_m}\cdot \vec{c_n}\\\end{pmatrix}<br>$$</p>
<blockquote>
<p>矩阵乘法 <strong>不遵守交换律</strong>，<strong>遵守分配率</strong></p>
</blockquote>
<h2 id="矩阵的转置"><a href="#矩阵的转置" class="headerlink" title="矩阵的转置"></a>矩阵的转置</h2><p>$$<br>P=\begin{pmatrix}0 &amp; 0\\4&amp;0\\5&amp;3\end{pmatrix}\ \ P^T=\begin{pmatrix}0 &amp;4&amp; 5\\0&amp;0&amp;3\end{pmatrix}\\ \  \\ 即A(a_{ij}),A^T(a_{ji})<br>$$</p>
<blockquote>
<p>转置的性质</p>
</blockquote>
<p>​    $(A+B)^T=A^T+B^T$</p>
<p>​    $(A\cdot B)^T=B^T\cdot A^T$</p>
<h2 id="更多的变换矩阵"><a href="#更多的变换矩阵" class="headerlink" title="更多的变换矩阵"></a>更多的变换矩阵</h2><blockquote>
<p>旋转变换<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312153308.png" style="zoom:50%;" /> $T\cdot \begin{pmatrix}x\\y\end{pmatrix}=\begin{pmatrix}x’\\y’\end{pmatrix}$</p>
</blockquote>
<blockquote>
<p><img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312153541.png" style="zoom:50%;" />    $\cos(\alpha)\cdot d=x\\ \sin(\alpha)\cdot d=y\\d为(x,y)的模$ 同理 $\cos(\alpha-\theta)\cdot d=x’\\ \sin(\alpha-\theta)\cdot d=y’$</p>
</blockquote>
<blockquote>
<p>得到x’和x，y’和y的关系</p>
</blockquote>
<p>$$<br>x’=\frac{cos(\alpha)cos(\theta)+sin(\alpha)sin(\theta)}{cos(\alpha)}x\\x’=cos(\theta)x+sin(\theta)\frac{sin(\alpha)}{cos(\alpha)}x=cos(\theta)x+sin(\theta)y\\同理：y’=cos(\theta)y-sin(\theta)\frac{cos(\alpha)}{sin(\alpha)}x=cos(\theta)x-sin(\theta)x\\所以\ \ T=\begin{pmatrix}cos(\theta) &amp; sin(\theta)\-sin(\theta) &amp; cos(\theta)\end{pmatrix}<br>$$</p>
<blockquote>
<p>可以通过单位向量容易理解一些</p>
<p>单位向量$\vec{e_1}=(0,1)^T,\vec{e_2}=(1,0)^T$，对$\vec{e_1}$的操作可以看做是对纵坐标的操作，对$\vec{e_2}$的操作就看做对横坐标的操作，那么我旋转$\theta$，很容易得到$\vec{e’_1}=(sin(\theta),cos(\theta)),\vec{e’_2}=( cos(\theta),-sin(\theta))$,也就得到了我们变换矩阵</p>
</blockquote>
<h2 id="单位矩阵"><a href="#单位矩阵" class="headerlink" title="单位矩阵"></a>单位矩阵</h2><p>$$<br>I_n=\begin{pmatrix}1 &amp; 0 &amp; … &amp; 0\\0 &amp; 1 &amp; … &amp; 0\... &amp; … &amp; …&amp; …\\0 &amp; 0 &amp; … &amp; 1\\\end{pmatrix}\\\ \ \\I_n=(i_{kj})\begin{cases}1 \ \ if \ \ k=j\\0 \ \ if\ \ k\neq j\end{cases}<br>$$</p>
<h2 id="矩阵的逆"><a href="#矩阵的逆" class="headerlink" title="矩阵的逆"></a>矩阵的逆</h2><p>$$<br>矩阵中AB=BA=I,则称B是A的逆矩阵，记做：B=A^{-1}<br>$$</p>
<blockquote>
<p>A称为可逆矩阵，或者叫 <strong>非奇异</strong> 矩阵（non-singular）</p>
<p>因为可逆矩阵居多，所以不可逆矩阵又叫<strong>奇异矩阵</strong>（singular）</p>
</blockquote>
<p>$$<br>如果 BA=I，则称B是A的左逆矩阵\\如果 AC=I，则称C是A的右逆矩阵\\如果一个矩阵A寄存在左逆矩阵B又存在右逆矩阵C，则B=C<br>$$</p>
<blockquote>
<p>因为AB=BA=I，所以<strong>可逆矩阵一定是方阵，非方阵一定不可逆</strong></p>
</blockquote>
<blockquote>
<p>对于矩阵A，如果存在逆矩阵B，则B<strong>唯一</strong></p>
</blockquote>
<p>$$<br>假设矩阵A存在两个不同的逆矩阵B,C\\AB=AC=I\\B(AB)=B(AC)\(BA)B=(BA)C\\B=C<br>$$</p>
<blockquote>
<p>$(A^T)^{-1}=(A^{-1})^T$,直接用定义证明</p>
</blockquote>
<h2 id="用矩阵表示空间"><a href="#用矩阵表示空间" class="headerlink" title="用矩阵表示空间"></a>用矩阵表示空间</h2><blockquote>
<p>矩阵乘以一个向量可以看做在矩阵这个空间中该向量的位置</p>
</blockquote>
<p>$$<br>\begin{pmatrix}4&amp;2\\1&amp;3\\\end{pmatrix}\cdot\begin{pmatrix}2\\2\\\end{pmatrix}\\以\vec{u}=\begin{pmatrix}4\\1\\\end{pmatrix},\vec{v}=\begin{pmatrix}2\\3\\\end{pmatrix}\\即以\vec{u}和\vec{v}构成的空间中，(2,2)^T所在的位置<br>$$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312170024.png" style="zoom:50%;" />

<blockquote>
<p>如上图所示，在$\vec{u},\vec{v}$构成的空间中，$(2,2)^T$即为u方向两个单位，v方向两个单位，最后相加得到的向量，最后在转为x-y坐标轴中，即得到$(12,8)^T$的结果</p>
</blockquote>
<h1 id="线性系统"><a href="#线性系统" class="headerlink" title="线性系统"></a>线性系统</h1><blockquote>
<p>什么是线性？</p>
<p>未知数只能是一次方项</p>
</blockquote>
<p>$$<br>\begin{cases}x+2y+4z &amp;=7\\3x+7y+2z &amp;=-11\\2x+3y+3z&amp;=1\end{cases}<br>$$</p>
<h2 id="高斯消元法"><a href="#高斯消元法" class="headerlink" title="高斯消元法"></a>高斯消元法</h2><blockquote>
<p>将上面三元一次方程组转化为矩阵</p>
</blockquote>
<p>$$<br>\begin{pmatrix}1&amp;2&amp;4&amp;7\\3&amp;7&amp;2&amp;-11\\2&amp;3&amp;3&amp;1\\\end{pmatrix}<br>$$</p>
<blockquote>
<p>该矩阵为增广矩阵：系数矩阵（前3列）+结果列</p>
<p>我们对其进行消元</p>
</blockquote>
<p>$$<br>\begin{pmatrix}1&amp;2&amp;4&amp;7\\3&amp;7&amp;2&amp;-11\\2&amp;3&amp;3&amp;1\\\end{pmatrix}\ \ \begin{pmatrix}1&amp;2&amp;4&amp;7\\0&amp;1&amp;-10&amp;-32\\2&amp;3&amp;3&amp;1\\\end{pmatrix}\ \ \begin{pmatrix}1&amp;2&amp;4&amp;7\\0&amp;1&amp;-10&amp;-32\\0&amp;-1&amp;-5&amp;-13\\\end{pmatrix}\ \ \begin{pmatrix}1&amp;2&amp;4&amp;7\\0&amp;1&amp;-10&amp;-32\\0&amp;0&amp;1&amp;3\\\end{pmatrix}<br>$$</p>
<blockquote>
<p>高斯消元法（主元就是每一行第一个非0的元素）</p>
<ul>
<li>第一行主元化为1</li>
<li>然后第二行上一行主元位置化为0，再该行主元化为1</li>
<li>依次类推进行消元</li>
</ul>
</blockquote>
<h2 id="高斯约旦消元法"><a href="#高斯约旦消元法" class="headerlink" title="高斯约旦消元法"></a>高斯约旦消元法</h2><blockquote>
<p>前向过程（从上到下）</p>
<ol>
<li>选择最上的主元，化为1</li>
<li>主元下面的所有行减去主元所在行的某个倍数，使得主元下面所有元素都为0</li>
</ol>
<p>后向过程（从下到上）</p>
<ol>
<li>选择最下的主元</li>
<li>主元上面的所有行减去主元所在行的某个背书，使得主元上面所有元素都为0</li>
</ol>
</blockquote>
<p>$$<br>\begin{pmatrix}<br>1&amp;0&amp;0&amp;2\<br>0&amp;1&amp;0&amp;-3\<br>0&amp;0&amp;1&amp;-4\<br>\end{pmatrix}<br>$$</p>
<h2 id="行最简形式"><a href="#行最简形式" class="headerlink" title="行最简形式"></a>行最简形式</h2><blockquote>
<p><strong>reduced row echelon form(RREF)</strong></p>
<p>即<strong>阶梯型矩阵</strong></p>
<p>非零行的第一个元素（主元）为<strong>1</strong></p>
<p>主元所在列的其他元素均为<strong>0</strong></p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312195348.png" style="zoom:50%;" />

<h2 id="齐次线性方程组"><a href="#齐次线性方程组" class="headerlink" title="齐次线性方程组"></a>齐次线性方程组</h2><blockquote>
<p>无常数项</p>
<p>至少有一个全零解</p>
</blockquote>
<p>$$<br>\begin{cases}<br>-x+2Y+3z &amp;=0\<br>x-4y-13z&amp;=0\<br>-3x+5y+4z&amp;=0\<br>\end{cases}<br>$$</p>
<blockquote>
<p>与上面解法相同，但可以把最后一列直接删掉，化为3*3的矩阵求解。</p>
</blockquote>
<h2 id="求解矩阵的逆"><a href="#求解矩阵的逆" class="headerlink" title="求解矩阵的逆"></a>求解矩阵的逆</h2><p>$$<br>A=\begin{pmatrix}<br>1&amp;2\\3&amp;4\<br>\end{pmatrix},求解A的逆矩阵\<br>设A^{-1}=\begin{pmatrix}<br>x_{11}&amp;x_{12}\\x_{21}&amp;x_{22}\<br>\end{pmatrix},即<br>\begin{pmatrix}1&amp;2\\3&amp;4\\\end{pmatrix}<br>\cdot<br>\begin{pmatrix}x_{11}&amp;x_{12}\\x_{21}&amp;x_{22}\\\end{pmatrix}<br>=<br>\begin{pmatrix}1&amp;0\\0&amp;1\\ \end{pmatrix}\<br>\begin{pmatrix}1&amp;2\\3&amp;4\\\end{pmatrix}<br>\cdot<br>\begin{pmatrix}x_{11}\\x_{21}\\\end{pmatrix}<br>=<br>\begin{pmatrix}1\\0\end{pmatrix}\ \<br>\begin{pmatrix}1&amp;2\\3&amp;4\\\end{pmatrix}<br>\cdot<br>\begin{pmatrix}x_{12}\\x_{22}\\\end{pmatrix}<br>=<br>\begin{pmatrix}0\\1\end{pmatrix}\<br>两边分别使用高斯约旦消元法<br>$$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312202913.png" style="zoom:67%;" />

<blockquote>
<p>消元之后我们可以发现左边右侧的*其实也就等于$(x_{11},x_{21})^T$,右边右侧等于$(x_{12},x_{22})^T$</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312203352.png" style="zoom:67%;" />

<blockquote>
<p>可以发现两边系数矩阵完全一样，我们可以构建2*4的增广矩阵，左边为系数矩阵，右边为单位矩阵</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312202606.png" style="zoom:67%;" />

<blockquote>
<p>这也就得到了$A^{-1}$的值</p>
</blockquote>
<h2 id="初等矩阵"><a href="#初等矩阵" class="headerlink" title="初等矩阵"></a>初等矩阵</h2><blockquote>
<p>对单位矩阵进行一次初等变换得到的结果矩阵</p>
<p><strong>通常记做E</strong></p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312213920.png" style="zoom:50%;" />

<blockquote>
<p>回忆使用高斯约旦消元法把矩阵化为最简形式的过程：</p>
<p>寻找一系列初等矩阵E，使得：</p>
</blockquote>
<p>$$<br>E_p\cdot … \cdot E_3 \cdot E_2 \cdot E_1 \cdot A=rref(A)<br>$$</p>
<h2 id="初等矩阵和可逆性"><a href="#初等矩阵和可逆性" class="headerlink" title="初等矩阵和可逆性"></a>初等矩阵和可逆性</h2><blockquote>
<p>因为初等变换是可逆的，所以初等矩阵必然是可逆的。</p>
<p>例如$\begin{pmatrix}k&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{pmatrix}$是将一个矩阵的第一行乘以K倍，那么他的可逆操作就是把第一行再乘以1/k，所以他的逆矩阵就是$\begin{pmatrix}\frac{1}{k}&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\end{pmatrix}$</p>
<p>同理可知其他初等矩阵的逆矩阵。</p>
</blockquote>
<h2 id="为什么矩阵的逆那么重要？"><a href="#为什么矩阵的逆那么重要？" class="headerlink" title="为什么矩阵的逆那么重要？"></a>为什么矩阵的逆那么重要？</h2><blockquote>
<p>对于线性系统： $Ax=b\ \ x=A^{-1}\cdot b$</p>
<p>如果在A不变，b会变化的条件下，可以大大加快计算速度</p>
<p>以下四个命题是等价的</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312220714.png" style="zoom:67%;" />

<h2 id="矩阵的LU分解"><a href="#矩阵的LU分解" class="headerlink" title="矩阵的LU分解"></a>矩阵的LU分解</h2><blockquote>
<p>将矩阵A分解为 $A=L\cdot U$</p>
<p>其中L: lower Triangle Matrix  下三角矩阵，U：Upper Triangle Matrix 上三角矩阵</p>
<p>以方阵为例$\begin{pmatrix}<em>&amp;0&amp;0&amp;0\\</em>&amp;<em>&amp;0&amp;0\\</em>&amp;<em>&amp;</em>&amp;0\*&amp;<em>&amp;</em>&amp;<em>\end{pmatrix}$ 为L，$\begin{pmatrix}</em>&amp;<em>&amp;</em>&amp;<em>\\0&amp;</em>&amp;<em>&amp;</em>\\0&amp;0&amp;<em>&amp;</em>\\0&amp;0&amp;0&amp;*\end{pmatrix}$ 为U</p>
<p>其中单位下三角矩阵$\begin{pmatrix}1&amp;0&amp;0&amp;0\*&amp;1&amp;0&amp;0\*&amp;<em>&amp;1&amp;0\\</em>&amp;<em>&amp;</em>&amp;1\end{pmatrix}$</p>
<p>高斯消元法的过程，就是通过初等变换，把一个矩阵变成了上三角矩阵。因此必然有一系列对应的逆向的初等变换，这些连续逆向的矩阵乘以单位矩阵的结果便是一个下三角矩阵L。</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312222100.png" style="zoom:67%;" />

<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312222504.png" style="zoom:67%;" />
$$
A=\begin{pmatrix}1&2&3\\4&5&6\\3&-3&5\end{pmatrix},L=\begin{pmatrix}1&0&0\\4&1&0\\3&3&1\end{pmatrix},U=\begin{pmatrix}1&2&3\\0&-3&-6\\0&0&14\end{pmatrix}
$$

<blockquote>
<p>矩阵能够进行LU分解的条件：高斯消元法中没有进行两行的互换。</p>
</blockquote>
<blockquote>
<p>时间复杂度的比较</p>
<p>在解Ax=b的过程中，LU分解：$O(0.5n^3)$</p>
<p>这个可以这么理解: LU分解就是先对A进行高斯消元，而高斯消元就是把主对角线下方的所有元素消成0，而主对角线下方大概有$0.5n^2$个元素，而每个元素消0都大概需要减去上一行某个倍数，而上一行大概是有n个元素，所以总的时间复杂度就为$O(0.5n^3)$，而对于L中，我们根本不需要算，直接逆向初等变化填入L中。</p>
</blockquote>
<blockquote>
<p>之后我们就可以把$Ax=b$转化为$L\cdot U\cdot x=b$，我们设$Ux=y\ \ 即L\cdot y=b$</p>
<p>$O(n^2)$求出y，我们可以这么理解，对于L，第一行我们可以直接得到$y_1$,那么得到$y_1$，在第二行也就可以直接得到$y_2$，依次类推看，每一行的未知y只需与前面求出来的y乘一下就好了，所以总共$O(0.5n^2)$求出y</p>
<p>那么我得到y之后$U\cdot x=y$，因为上三角矩阵和下三角矩阵求法相同，所以与求y的时间复杂度相同</p>
<p>最终 LU分解：$O(0.5n^3)+2*O（0.5n^2）$</p>
</blockquote>
<blockquote>
<p>对比求解矩阵的逆 大概$O(2*n^3)$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200312225804.png" style="zoom:67%;" />

<p>我们使用高斯约旦消元法，要把左侧的系数矩阵化为单位矩阵，相当于每个元素都要加减某一行的某个倍数，那么总共有$n^2$个元素，而每次乘以一个倍数，因为是增广矩阵，所以每次乘法都乘了2n个元素，所以总共时间复杂度约为$O(2*n^3)$</p>
</blockquote>
<blockquote>
<p>可见LU分解效率较正常求解较高。</p>
</blockquote>
<h2 id="PLU分解"><a href="#PLU分解" class="headerlink" title="PLU分解"></a>PLU分解</h2><blockquote>
<p>上文我们说过，LU分解中不能进行行的交换操作，因为一旦交换，必然高斯消元的逆操作矩阵不可能是一个下三角矩阵，因为如果我们进行了行交换，逆操作矩阵必然也要进行行交换，这样我们就得不到LU矩阵。</p>
<p>那么我们可以在找一个初等变换矩阵，把进行的行变换在逆操作一次，这样就又得到了LU矩阵。我们把这个进行行变换的初等变换矩阵叫做置换矩阵P，那么，我们就得到$A=P\cdot L\cdot U$。</p>
</blockquote>
<blockquote>
<p>矩阵P不一定是一个初等变换矩阵，可能是多个初等变换矩阵相乘的结果。</p>
<p>因此，我们很多函数库中都没有LU分解，只有PLU分解。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  （更广泛，但是不是所有矩阵都可以进行PLU分解）</p>
<p>如果需要列变换，则添加额外的P’矩阵。</p>
<p>即$A=P\cdot L\cdot U \cdot P’$,成为PLUP’分解.</p>
</blockquote>
<h2 id="列交换"><a href="#列交换" class="headerlink" title="列交换"></a>列交换</h2><blockquote>
<p>矩阵右乘一个置换矩阵，所得结果为交换后的矩阵</p>
</blockquote>
<p>$$<br>\begin{pmatrix}<br>1&amp;2&amp;3\\4&amp;5&amp;6\\7&amp;8&amp;9<br>\end{pmatrix}\cdot<br>\begin{pmatrix}<br>1&amp;0&amp;0\\0&amp;0&amp;1\\0&amp;1&amp;0<br>\end{pmatrix}=<br>\begin{pmatrix}<br>1&amp;3&amp;2\\4&amp;6&amp;5\\7&amp;9&amp;8<br>\end{pmatrix}<br>$$</p>
<blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313132144.png" style="zoom:50%;" />

<p>我们可以把原矩阵以列的角度来看，可以分成四列，置换矩阵也分成三列。</p>
<p>但是我们原矩阵的第一列成语置换矩阵的第一列时，我们把置换矩阵的列又拆成行数个数的变量，</p>
<p>那么我们就得到$\begin{pmatrix}1\\4\\7\end{pmatrix}\cdot x_1+\begin{pmatrix}2\\5\\8\end{pmatrix}\cdot y_1+\begin{pmatrix}3\\6\\9\end{pmatrix}\cdot z_1$，本例中$y_1=z_1=0,x_1=1,$就相当于只取出了第一列所以结果矩阵也就是$\begin{pmatrix}1\\4\\7\end{pmatrix}$，之后类似，$\begin{pmatrix}0\\0\\1\end{pmatrix}$就是只取出第三列。就很容易得到交换后的结果。</p>
</blockquote>
<h1 id="线性组合"><a href="#线性组合" class="headerlink" title="线性组合"></a>线性组合</h1><blockquote>
<p>$$<br>对于若干个n维向量 \vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_p}\<br>k_1\cdot \vec{v_1}+k_2\cdot \vec{v_2}+k_3\cdot \vec{v_3}+…+k_p\cdot\vec{v_p}\<br>称为这些向量的一个线性组合<br>$$</p>
<p>例如三维空间中间中的任意一个向量都可以看做一个基于坐标轴标准单位向量的线性组合<br>$$<br>\vec{e_1}=(1,0,0)^T,\vec{e_2}=(0,1,0)^T,\vec{e_3}=(0,0,1)^T\<br>那么任意一个向量 \vec{v}=(x,y,z)=x\cdot (1,0,0)^T+y\cdot(0,1,0)^T+z\cdot(0,0,1)^T\<br>=x\cdot \vec{e_1}+y\cdot \vec{e_2}+z\cdot \vec{e_3}<br>$$</p>
</blockquote>
<h2 id="线性相关与线性无关"><a href="#线性相关与线性无关" class="headerlink" title="线性相关与线性无关"></a>线性相关与线性无关</h2><p>$$<br>对于若干个n维向量 \vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_p}存在一组k不全为0，使得\<br>k_1\cdot \vec{v_1}+k_2\cdot \vec{v_2}+k_3\cdot \vec{v_3}+…+k_p\cdot\vec{v_p}=0\<br>则称\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_p}线性相关<br>$$</p>
<blockquote>
<p>假设存在这样的一个线性相关组合</p>
<p>$-7/2\cdot \vec{r_1}-1/2\cdot \vec{r_2}+\vec{r_3}=0$</p>
<p>那么我们可以转换为$\vec{r_3}=7/2\cdot \vec{r_1}+1/2\cdot \vec{r_2}$，即r3可以表示成r1和r2的线性组合</p>
</blockquote>
<blockquote>
<p><strong>如果$\vec{v_1},\vec{v_2},\vec{v_3},…,\vec{v_n}$线性相关&lt;=&gt;其中一个向量可以写成其他向量的线性组合</strong></p>
</blockquote>
<p>$$<br>对于若干个n维向量 \vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_p}只有K全部为0时，才有\<br>k_1\cdot \vec{v_1}+k_2\cdot \vec{v_2}+k_3\cdot \vec{v_3}+…+k_p\cdot\vec{v_p}=0\<br>则称\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_p}线性无关<br>$$</p>
<blockquote>
<p>m个n维向量$\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_m}$,若m&gt;n，则$\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_m}$ 线性相关</p>
</blockquote>
<p>$$<br>是否存在k_1,k_2,…,k_m不全为0，满足k_1\cdot \vec{v_1}+k_2\cdot \vec{v_2}+k_3\cdot \vec{v_3}+…+k_m\cdot\vec{v_m}=0\<br>因为\vec{v}是n维向量，所以等式可以化为：\<br>k_1\begin{pmatrix}v_{11}\\v_{12}\...\\v_{1n}\end{pmatrix}+<br>k_2\begin{pmatrix}v_{21}\\v_{22}\...\\v_{2n}\end{pmatrix}+<br>…+k_m\begin{pmatrix}v_{m1}\\v_{m2}\...\\v_{mn}\end{pmatrix}=0\<br>又可以根据之前列的视角，转化为：\<br>\begin{pmatrix}v_{11}&amp;v_{21}&amp;…&amp;v_{m1}\\v_{12}&amp;v_{22}&amp;…&amp;v_{m2}<br>\...&amp;…&amp;&amp;…\\v_{1n}&amp;v_{2n}&amp;…&amp;v_{mn}\end{pmatrix}\cdot<br>\begin{pmatrix}k_1\\k_2\\k_3\...\\k_m\end{pmatrix}=0<br>$$</p>
<blockquote>
<p>即齐次线性方程组求解，那我们直接对系数矩阵处理。</p>
<p>因为 <strong>m&gt;n</strong>，所以系数矩阵的列数大于行数，非零行最多只用n行，小于未知数的个数m，所以必然是还有无数解的，而不仅仅只有唯一的零解，得证。</p>
<p>那什么时候线性无关呢？很显然m=n且原矩阵可逆即原矩阵的行最简形式为单位矩阵。</p>
<p>我们总结一下几个等价关系。</p>
<ul>
<li>矩阵A可逆（A是非奇异矩阵）</li>
<li>线性系统Ax=0只有唯一解，x=0</li>
<li>$rref(A)=I$</li>
<li>A可以表示成一系列初等矩阵的乘积</li>
<li>Ax=b只有唯一解</li>
<li>方阵A的列向量线性无关</li>
</ul>
</blockquote>
<h2 id="生成空间"><a href="#生成空间" class="headerlink" title="生成空间"></a>生成空间</h2><blockquote>
<p>二维空间中的任意向量都可以表示为$\vec{u}和\vec{v}$的线性组合</p>
<p>即我们可以说$\vec{u}和\vec{v}$可以生成整个二维空间<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313171739.png" style="zoom:67%;" /></p>
<p>推论：若空间中的所有向量，都可以被表示成$\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_p}$的线性组合那么称这些向量可以生成这个空间。</p>
<p>若m个向量生成n维空间，m最小为n（可以用反证法证明，假设m&lt;n，推翻）</p>
</blockquote>
<h2 id="空间的基"><a href="#空间的基" class="headerlink" title="空间的基"></a>空间的基</h2><blockquote>
<p>n个n维向量 $\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_n}$，若他们是这个n维空间的 <strong>基</strong> 等价于</p>
<ol>
<li>$\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_n}$生成整个n维空间（加到上面的几个等价关系中）</li>
<li>$\vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_n}$线性无关</li>
</ol>
</blockquote>
<blockquote>
<p>例如上图中u,v向量便是这个二维空间的一组基</p>
</blockquote>
<blockquote>
<p>在n维空间，如果给定一组基。</p>
<p>任何一个向量都可以表示成这组基的线性组，<strong>且表示方法唯一</strong></p>
<p>证明就通过上面的几个等价关系，因为是空间的基，那么线性无关，这就可以退出Ax=b只有唯一解，即证。</p>
</blockquote>
<h1 id="空间"><a href="#空间" class="headerlink" title="空间"></a>空间</h1><blockquote>
<p>什么是空间？</p>
<p>空间是一个集合。我们平时说的空间其实是欧几里得空间</p>
<p><strong>欧几里得空间</strong></p>
<p>欧几里得空间就是有序实数元祖的集合 $R^n(n表示n维空间)$</p>
<p>空间中的元素是“向量”，即有序实数元祖</p>
<p>那什么又叫做向量，是什么让向量成为向量。</p>
<p>我们这边要定义两种运算，加法和数量乘法，然后基于这两种运算要满足十个性质的才是向量空间。</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313202840.png" style="zoom:70%;" />

<h2 id="广义向量空间"><a href="#广义向量空间" class="headerlink" title="广义向量空间"></a>广义向量空间</h2><blockquote>
<p>我们通常说向量其实就是指欧几里得空间的元素</p>
<p>为了区别，通常把$\begin{pmatrix}1&amp;0\\0&amp;b\end{pmatrix}$的向量空间，成为$\begin{pmatrix}1&amp;0\\0&amp;b\end{pmatrix}$</p>
</blockquote>
<blockquote>
<p>例如2*2方阵，也可以构成一个向量空间，完全满足上面的十个性质，所以所有的2 * 2方阵就构成一个向量空间</p>
<p>反例：$\begin{pmatrix}1&amp;0\\0&amp;b\end{pmatrix}$这样形式的矩阵就无法构成向量空间</p>
<p>因为他就不满足一开始的封闭率（即两个向量想加的结果也为同样的向量)，而两个这样的向量想加的话，左上角的元素必然不固定为1，所以就违背了封闭性的准则，固然就不能构成向量空间。</p>
</blockquote>
<h2 id="子空间"><a href="#子空间" class="headerlink" title="子空间"></a>子空间</h2><blockquote>
<p>假设V是一个向量空间，如果<strong>S是V的子集</strong>，且<strong>S还是一个向量空间</strong>，则称S是V的一个<strong>子空间</strong></p>
<p>例如所有的2阶方阵形成一个向量空间V。</p>
<p>所有如下形式的矩阵$\begin{pmatrix}a&amp;0\\0&amp;b\end{pmatrix}$也形成一个向量空间S，且该形式的矩阵为2阶方阵的子集</p>
<p>所以向量空间S是V的一个子空间。</p>
</blockquote>
<blockquote>
<p>我们可以对上面的定义进行简化</p>
<p>假设V是一个向量空间，如果<strong>S是V的子集</strong>，且<strong>S对加法和数量乘法具有封闭性</strong>，则称S是V的一个<strong>子空间</strong>（证明就是通过V的十个性质加上S的封闭性来推，这里就不赘述了）</p>
</blockquote>
<blockquote>
<p>我们以二维欧几里得空间为例。</p>
<p>显然，一个过原点的直线是该二维欧几里得空间的一个子空间，因为在这条直线上的向量满足加法和数量乘法的封闭性。</p>
<p>但是，我们来看一个不过原点的直线。我们都知道，欧几里得空间中的向量是从原点出发，所以原点到一个不过原点的直线必然是不满足加法和数量乘法的封闭性。</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313215959.png" style="zoom:70%;" />

<p>那如果是过原点的射线呢，那也是不可以的，虽然射线上的向量都满足加法的封闭性，但是乘法的封闭性是不满足的，例如我设系数K=-1，那么$k\cdot \vec{u}$必然是反向与射线的，从而不在射线上，所以不满足子空间的要求</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200313220027.png" style="zoom:67%;" />
</blockquote>
<blockquote>
<p>推广来说：</p>
<p>对于n维空间来说：</p>
<p>过原点的一个m维空间（m&lt;n），是n维空间的一个子空间</p>
<p><strong>机器学习中我们常用降维的思路，将高维的数据降维成原数据空间的子空间，这样也不会有信息丢失。</strong></p>
</blockquote>
<h2 id="维度"><a href="#维度" class="headerlink" title="维度"></a>维度</h2><blockquote>
<p>一个空间的基中，向量的个数，成为 <strong>维度</strong></p>
<p>二维欧几里得空间的维度为2。$e_1=(1,0)^T\ \ e_2=(0,1)^T,dim(R^2)=2$</p>
<p>被向量$\vec{u}=(2,0,0);\vec{v}=(-1,0,0);\vec{w}=(0,0,1)$生成的空间维度为多少？</p>
<p>显然$\vec{u}和 \vec{v}$线性相关，所以可以删除u或者v，这样基就为u和w，那么显然该空间维度为2.</p>
</blockquote>
<h2 id="行空间"><a href="#行空间" class="headerlink" title="行空间"></a>行空间</h2><blockquote>
<p>给出一组n维向量$ \vec{v_1} ,\vec{v_2} ,\vec{v_3},…, \vec{v_p}$，其生成空间的维度是多少？</p>
<p>我们只需找出这组向量有多少和其他向量线性相关</p>
</blockquote>
<blockquote>
<p>我们将这组向量按照行排列成一个矩阵。</p>
<p>执行Gauss-Jordan消元法（化为RREF），非零行的个数即为生成空间的维度。</p>
</blockquote>
<p>$$<br>被向量\vec{u}=(2,0,0);\vec{v}=(-1,0,0);\vec{w}=(0,0,1)生成的空间维度为多少？\<br>\begin{pmatrix}\vec{u}\\\vec{v}\\\vec{w}\end{pmatrix}=\begin{pmatrix}2&amp;0&amp;0\-1&amp;0&amp;0\\0&amp;0&amp;1\end{pmatrix}=\begin{pmatrix}1&amp;0&amp;0\-1&amp;0&amp;0\\0&amp;0&amp;1\end{pmatrix}=\begin{pmatrix}1&amp;0&amp;0\\0&amp;0&amp;0\\0&amp;0&amp;1\end{pmatrix}=\begin{pmatrix}1&amp;0&amp;0\\0&amp;0&amp;1\\0&amp;0&amp;0\end{pmatrix}\<br>那么我们可以看到生成了两个非零行，所以这些向量生成的空间维度就为2<br>$$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314110945.png" style="zoom:67%;" />

<blockquote>
<p>对于一个矩阵，行向量生成的空间，称为<strong>行空间（Row Space）</strong></p>
<p>一个矩阵的行最简形式的非零行数量称为矩阵的<strong>行秩（Row Rank）</strong></p>
<p>行空间的维度，为矩阵的行秩</p>
<p>一个矩阵的行最简形式的非零行向量，是构成行空间的一组基</p>
</blockquote>
<h2 id="列空间"><a href="#列空间" class="headerlink" title="列空间"></a>列空间</h2><blockquote>
<p>继续以上面三个向量为例</p>
<p>以列向量的形式表示</p>
</blockquote>
<p>$$<br>\vec{u}=(2,0,0);\vec{v}=(-1,0,0);\vec{w}=(0,0,1)\<br>\begin{pmatrix}2&amp;-1&amp;0\\0&amp;0&amp;0\\0&amp;0&amp;1\end{pmatrix}\cdot \begin{pmatrix}k_1\\k_2\\k_3\end{pmatrix}=0\<br>\begin{pmatrix}2&amp;-1&amp;0\\0&amp;0&amp;0\\0&amp;0&amp;1\end{pmatrix}=\begin{pmatrix}1&amp;-0.5&amp;0\\0&amp;0&amp;0\\0&amp;0&amp;1\end{pmatrix}<br>$$</p>
<blockquote>
<p>我们可以看到第一列和第三列有主元列，而第二列没有</p>
<p>主元列的个数即为维度</p>
<p>主元列的个数，为 <strong>列秩（Column Rank）</strong></p>
</blockquote>
<blockquote>
<p>对于一个矩阵，列向量生成的空间，称为<strong>列空间（Row Space）</strong></p>
<p>其中行最简形式主元列的对应原矩阵的列就是列空间的一组基</p>
</blockquote>
<h2 id="矩阵的秩和矩阵的逆"><a href="#矩阵的秩和矩阵的逆" class="headerlink" title="矩阵的秩和矩阵的逆"></a>矩阵的秩和矩阵的逆</h2><blockquote>
<p>矩阵的行秩=矩阵的列秩</p>
</blockquote>
<p>$$<br>对于矩阵A=\begin{pmatrix}a_{11}&amp;a_{12}&amp;…&amp;a_{1n}\\a_{21}&amp;a_{22}&amp;…&amp;a_{2n}\...&amp;…&amp; &amp;…\\a_{m1}&amp;a_{m2}&amp;…&amp;a_{mn}\\\end{pmatrix}\<br>我们可以化成\begin{pmatrix}1&amp;0&amp;…&amp;0&amp;f_{00}&amp;…&amp;f_{0j}\\0&amp;1&amp;…&amp;0&amp;f_{10}&amp;…&amp;f_{1j}\...&amp;…&amp;…&amp;…&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;1&amp;f_{r0}&amp;…&amp;f_{rj}\\0&amp;0&amp;…&amp;0&amp;0&amp;…&amp;0\...&amp;…&amp;…&amp;…&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;0&amp;0&amp;…&amp;0\end{pmatrix}，即一个行最简形式\<br>我们可以发现，左上角为一个单位矩阵I，右上角为自由列矩阵（非主元列）,单位矩阵和自由列下方便是全0列。\<br>那么，因为单位矩阵I是方阵，所以主元列个数为r列=非零行行数。\<br>所以矩阵的行秩=矩阵的列秩<br>$$</p>
<blockquote>
<p><strong>矩阵的秩(Rank)</strong></p>
<p>行秩：行最简形式的非零行数</p>
<p>列秩：行最简形式主元列数</p>
</blockquote>
<p>$$<br>\vec{u}=(1,1,2),\vec{v}=(2,2,3),\vec{w}=(3,3,4)的生成空间的维度？\<br>\begin{pmatrix}1&amp;1&amp;2\\2&amp;2&amp;3\\3&amp;3&amp;4\end{pmatrix}\<br>我们从行的角度来看不容易看出是否线性相关，\\但是从列的角度来看，第一列和第二列是一样的，所以线性相关\\可以删去一列，那么很明显就是可以得出生成空间维度为2<br>$$</p>
<blockquote>
<p>对于一个n阶方阵，矩阵的秩r=n 则称为 <strong>满秩</strong></p>
<p>此时，该方阵的行最简形式必然是单位矩阵I。</p>
</blockquote>
<h2 id="零空间"><a href="#零空间" class="headerlink" title="零空间"></a>零空间</h2><blockquote>
<p>一个齐次线性方程组的所有解，形成一个向量空间。</p>
<p>称这个空间，为 <strong>零空间（Null Space）</strong></p>
<p><strong>A的零空间，就是AX=0中，所有x组成的空间</strong></p>
</blockquote>
<blockquote>
<p>换个角度来看</p>
<p>我们之前说过可以把矩阵看做对向量的<strong>函数（变换）</strong>：</p>
<p>因此，<strong>零空间是一个集合，而该集合中的所有向量，在矩阵A的变换下，都将映射到零点。</strong></p>
<p>我们可以再换一个角度</p>
<p>零空间是一个集合，这个集合中的所有的向量，和矩阵A的行向量<strong>点乘</strong>结果都为<strong>0</strong>。</p>
<p>点乘为0，我们之前有说过，两个向量点乘为0，说明两个向量<strong>垂直</strong></p>
<p>那么零空间这个集合中所有的向量，都和A的行空间中所有向量正交（垂直）</p>
<p>即 <strong>A的零空间和A的行空间正交</strong></p>
</blockquote>
<blockquote>
<p>那么，怎么求零空间的维度和基呢？</p>
</blockquote>
<p>$$<br>\begin{pmatrix}1&amp;2&amp;3&amp;4&amp;5&amp;6\\27&amp;28&amp;29&amp;30&amp;31&amp;32\\15&amp;16&amp;17&amp;18&amp;19&amp;20\\31&amp;32&amp;33&amp;34&amp;35&amp;36\<br>45&amp;46&amp;47&amp;48&amp;49&amp;50\end{pmatrix}-&gt;\begin{pmatrix}1&amp;0&amp;-1&amp;-2&amp;-3&amp;-4\\0&amp;1&amp;2&amp;3&amp;4&amp;5\\0&amp;0&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;0\<br>0&amp;0&amp;0&amp;0&amp;0&amp;0\end{pmatrix}\<br>=\begin{pmatrix}1\-2\\1\\0\\0\\0\end{pmatrix}x_3+<br>\begin{pmatrix}2\-3\\0\\1\\0\\0\end{pmatrix}x_4+<br>\begin{pmatrix}3\-4\\0\\0\\1\\0\end{pmatrix}x_5+<br>\begin{pmatrix}4\-5\\0\\0\\0\\1\end{pmatrix}x_6<br>$$</p>
<blockquote>
<p>这四个向量所能表示表示出来的线性方程组，就是满足Ax=0的解，所以这四个向量构成的空间为A的零空间</p>
<p>很明显这四个向量都线性无关，所以零空间的维度为4.</p>
</blockquote>
<blockquote>
<p>通过上面的例子可以看出</p>
<p>对于一个m*n的矩阵，将其化为行最简形式</p>
<p>主元列数为列空间的维度，自由列数为零空间的维度</p>
<p><strong>即列空间的维度+零空间的维度=n</strong></p>
<p><strong>秩（rank）+零化度（Nullity）=n</strong>  （<strong>秩-零化度定理</strong>）</p>
</blockquote>
<h2 id="左零空间"><a href="#左零空间" class="headerlink" title="左零空间"></a>左零空间</h2><blockquote>
<p>左零空间即为$A^T$的零空间，记做$Null(A^T)$</p>
<p>那么，我们为什么叫他左零空间呢？<br>$$<br>根据定义 A^Tx=0\<br>(A^Tx)^T=0\<br>x^TA=0<br>$$<br>所以叫做A的左零空间</p>
<p>那么具体怎么求左零空间的基，维度，暂时不考虑，只做初步了解。</p>
</blockquote>
<h1 id="正交"><a href="#正交" class="headerlink" title="正交"></a>正交</h1><h2 id="正交基和标准正交基"><a href="#正交基和标准正交基" class="headerlink" title="正交基和标准正交基"></a>正交基和标准正交基</h2><blockquote>
<p><strong>正交向量组</strong></p>
<p>一组向量，如果两两正交，则称为正交向量组</p>
<p>正交非零向量组一定<strong>线性无关</strong>。</p>
<p>正交基</p>
<p>也就是如果一个空间的一组基两两正交，则称这组基为一组正交基</p>
<p>模为1的正交基称为<strong>标准正交基</strong></p>
</blockquote>
<h2 id="一维投影"><a href="#一维投影" class="headerlink" title="一维投影"></a>一维投影</h2><blockquote>
<p>如果给定一个空间的一组基，我们希望进一步找到这个空间的一组正交基</p>
<p>进一步，标准正交基</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314173253.png" style="zoom: 80%;" />
$$
我们可以吧\vec{v}转化成\vec{p}+(\vec{v}-\vec{p})，那么我们关键就是求出\vec{p}\\
我们知道\vec{u}\cdot \vec{v}=\parallel\vec{u}\parallel\cdot\parallel\vec{v}\parallel\cdot cos(\theta)\\
\parallel\vec{p}\parallel=\parallel\vec{v}\parallel\cdot cos(\theta)=\frac{\vec{u}\cdot \vec{v}}{\parallel\vec{u}\parallel}\\
\vec{p}的方向也就是\vec{u}的方向：\frac{\vec{u}}{\parallel\vec{u}\parallel}\\
所以\vec{p}=\frac{\vec{u}\cdot \vec{v}}{\parallel\vec{u}\parallel^2}\vec{u}\\
这样一组正交基 \vec{v}-\vec{p},\vec{u}就得到了
$$

<h2 id="高维投影和Gram-Schmidt过程"><a href="#高维投影和Gram-Schmidt过程" class="headerlink" title="高维投影和Gram Schmidt过程"></a>高维投影和Gram Schmidt过程</h2><blockquote>
<p>我们就以三维空间为例来说明高维投影</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314194838.png" style="zoom:80%;" />

<blockquote>
<p>如图所示，我们得到$\vec{w},\vec{v},\vec{u}$这三个向量构成的一组基。</p>
<p>那么我们先将$\vec{u}和\vec{v}$两个向量处理成正交基，将$\vec{u}$记为$\vec{p_1}$，$\vec{v}$转化后的正交向量记为$\vec{p_2}$</p>
<p>下面我们就需要让$\vec{w}$与$\vec{p_1}和\vec{p_2}$相互正交，很显然，即将$\vec{w}$转换为与$\vec{p_1}和\vec{p_2}$构成空间（平面）垂直的的向量即可。</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314195947.png" style="zoom:80%;" />

<blockquote>
<p>那么我们现在主要就是要求出$\vec{p}$,如何求出呢？</p>
<p>我们以$\vec{p}$的终点向$\vec{p_1}$$\vec{p_2}$做垂线，所得向量$\vec{a}$和$\vec{b}$</p>
<p>我们又不难发现，$\vec{a}$和$\vec{b}$就分别是$\vec{w}$在$\vec{p_1}$和$\vec{p_2}$上的一维投影，根据上面的一维投影的公式，也很容易得到$\vec{a}$和$\vec{b}$的值，我们也就得到了$\vec{p}$的值</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314200715.png" style="zoom:80%;" />
$$
\begin{align}\vec{p}&=k_1\cdot \vec{p_1}+k_2\cdot \vec{p_2}=\vec{a}+\vec{b}\\&=
\frac{\vec{w}\cdot \vec{p_1}}{\parallel\vec{p_1}\parallel^2}\cdot\vec{p_1}+
\frac{\vec{w}\cdot \vec{p_2}}{\parallel\vec{p_2}\parallel^2}\cdot\vec{p_2}\\
\vec{w}-\vec{p}&=\vec{w}-\frac{\vec{w}\cdot \vec{p_1}}{\parallel\vec{p_1}\parallel^2}\cdot\vec{p_1}-
\frac{\vec{w}\cdot \vec{p_2}}{\parallel\vec{p_2}\parallel^2}\cdot\vec{p_2}\\
而\ \ \vec{p_1}&=\vec{u}\\
\vec{p_2}&=\vec{v}-\frac{\vec{v}\cdot \vec{u}}{\parallel\vec{u}\parallel^2}\cdot\vec{u}
\end{align}
$$

<blockquote>
<p>如果已知一组基：$\vec{v_1},\vec{v_2},\vec{v_3},…,\vec{v_n}$,求一组正交基.</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200314201839.png" style="zoom:75%;" />

<blockquote>
<p>其中$\vec{p_n}$即为$\vec{v_n}$减去其在上一维子空间上的投影</p>
<p>这个算法过程即为 <strong>格拉姆-施密特过程（Gram-Schmidt）</strong></p>
</blockquote>
<h2 id="标准正交基的性质"><a href="#标准正交基的性质" class="headerlink" title="标准正交基的性质"></a>标准正交基的性质</h2><blockquote>
<p>一组n维标准正交基$\vec{v_1},\vec{v_2},\vec{v_3},…,\vec{v_n}$</p>
<p>按照<strong>列的方式</strong>排列成一个n阶方阵Q，称Q为<strong>标准正交矩阵</strong></p>
</blockquote>
<blockquote>
<p>标准正交矩阵的重要性质：</p>
<ul>
<li><p>$Q^T\cdot Q=I$（证明很容易，就不写了,列出来一乘就发现了）</p>
</li>
<li><p>Q的各列线性无关，因为Q是一组基，必然是线性无关的</p>
</li>
<li><p>既然线性无关，那根据之前的那一系列等价条件可得，Q是可逆的</p>
<p>$Q^T$是Q的左逆，那么$Q^T$也必然是Q的右逆，即$Q^T$是Q的逆</p>
<p>即<strong>$Q^{-1}=Q^T$</strong> （PCA把高维空间映射到低维空间中后就是通过这个性质再返回至高维空间）</p>
</li>
</ul>
</blockquote>
<h2 id="矩阵的QR分解"><a href="#矩阵的QR分解" class="headerlink" title="矩阵的QR分解"></a>矩阵的QR分解</h2><blockquote>
<p>A=QR</p>
<p>其中Q是标准正交矩阵，R为一个上三角矩阵（条件：A的各个列向量线性无关）<br>$$<br>Ax=b\ \ \ (QR)x=b\\Q^{-1}QRx=Q^{-1}b\<br>Rx=Q^Tb<br>$$</p>
</blockquote>
<p>$$<br>A=(\vec{a_1},\vec{a_2},…,\vec{a_n})\<br>对A的各个列向量执行Gram-Schmidt过程，得到\vec{p_1},\vec{p_2},…,\vec{p_n}\<br>再进行规范化，得到\vec{q_1},\vec{q_2},…,\vec{q_n}\<br>\vec{p_1}=\vec{a_1}=\parallel\vec{p_1}\parallel\vec{q_1}=r_{11}\vec{q_1}\<br>\vec{p_2}=\vec{a_2}-\frac{\vec{a_2}\cdot \vec{p_1}}{\parallel\vec{p_1}\parallel^2}\cdot\vec{p_1}=\parallel\vec{p_2}\parallel\vec{q_2}\<br>\vec{a_2}=\frac{\vec{a_2}\cdot \vec{p_1}}{\parallel\vec{p_1}\parallel^2}\cdot\parallel\vec{p_1}\parallel\vec{q_1}+\parallel\vec{p_2}\parallel\vec{q_2}=r_{21}\vec{q_1}+r_{22}\vec{q_2}\<br>\vec{a_3}=r_{31}\vec{q_1}+r_{32}\vec{q_2}+r_{33}\vec{q_3}\...\<br>\vec{a_n}={r_{n1}\vec{q_1}+r_{n2}\vec{q_2}+r_{n3}}\vec{q_3}+…+r_{nn}\vec{q_n}<br>$$</p>
<p>$$<br>\begin{align}A&amp;=(\vec{a_1},\vec{a_2},…,\vec{a_n})\<br>&amp;=(r_{11}\vec{q}\ \ r_{21}\vec{q_1}+r_{22}\vec{q_2}\ \ …\ \ {r_{n1}\vec{q_1}+r_{n2}\vec{q_2}+r_{n3}}\vec{q_3}+…+r_{nn}\vec{q_n})\<br>&amp;=(r_{11}\vec{q_1}\ \ r_{21}+\vec{q_1}\ \ …\ \ r_{n1}\vec{q_1})\<br>&amp;+(0\ \ r_{22}+\vec{q_2}\ \ …\ \ r_{n2}\vec{q_2})\\ &amp;…\<br>&amp;+(0\ \ 0\ \ …\ \ r_{nn}\vec{q_n})</p>
<p>\end{align}<br>$$</p>
<blockquote>
<p>我们已经把A转化为多个矩阵的和，我们之前有通过列的角度将两个矩阵的乘法转化为矩阵的和</p>
<p>那么，我们现在逆向操作，把A，这些矩阵的和转换为一些矩阵的乘</p>
</blockquote>
<p>$$<br>A=(\vec{q_1},\vec{q_2},…,\vec{q_n})\cdot \begin{pmatrix}r_{11}&amp;r_{21}&amp;…&amp;r_{n1}\\0&amp;r_{22}&amp;…&amp;r_{n2}\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;r_{nn}\end{pmatrix}<br>$$</p>
<blockquote>
<p>现在我们已经将A转换为QR</p>
<p>但是我们没有必要去算R，我们可以通过下面的操作直接得到R</p>
</blockquote>
<p>$$<br>A=QR\<br>R=Q^{-1}A\<br>R=Q^TA<br>$$</p>
<h1 id="坐标系"><a href="#坐标系" class="headerlink" title="坐标系"></a>坐标系</h1><blockquote>
<p>如果给定向量空间V中的一组基$B={\vec{b_1},\vec{b_2},\vec{b_3},…,\vec{b_n}}$，以及V中的一个向量x，则x一定可以被这组基线性表示。</p>
<p>假设 $\vec{x}=c_1\vec{b_1},c_2\vec{b_2},c_3\vec{b_3},…,c_n\vec{b_n}$</p>
<p>则称x在这组基B下的坐标为：$(c_1,c_2,…,c_n)^T$，记为$[\vec{x}]_B$</p>
</blockquote>
<p>$$<br>B=\{\vec{u},\vec{v}\} \<br>\vec{x}=2\vec{u}+2\vec{v} \<br>\ [\vec{x}]_B=(2,2)^T<br>$$</p>
<blockquote>
<p>$\epsilon=\{\vec{e_1},\vec{e_2}\}$为标准基   我们也叫作标准坐标系</p>
</blockquote>
<h2 id="坐标系转换"><a href="#坐标系转换" class="headerlink" title="坐标系转换"></a>坐标系转换</h2><blockquote>
<p>假设有一组基：$B={\vec{b_1},\vec{b_2},\vec{b_3},…,\vec{b_n}}$，设立矩阵$P_B=(\vec{b_1}\ \ \vec{b_2}\ \ \vec{b_3}…\vec{b_n})$（坐标转换矩阵）</p>
<p>在这组基下的一个向量$[\vec{x}]<em>B$，有：$[\vec{x}]</em>{\epsilon}=P_B[\vec{x}]_B$<br>$$<br>[\vec{x}]_B=\begin{pmatrix}2\\2\end{pmatrix},[\vec{x}]_\epsilon=\begin{pmatrix}12\\8\end{pmatrix}\<br>P_B=\begin{pmatrix}4&amp;2\\1&amp;3\end{pmatrix}\<br>\vec{b_1}=(4,1)^T=4\vec{e_1}+1\vec{e_2},\vec{b_2}=(2,3)^T=2\vec{e_1}+3\vec{e_2} \\<br>[\vec{x}]_B=[(2,2)^T]_B=2\vec{u}+2\vec{v}=12\vec{e_1}+8\vec{e_2}<br>$$<br>再由B坐标系转到标准坐标系</p>
<p>即等式两边同时乘以一个$P_B^{-1}$</p>
<p>$[\vec{x}]_{\epsilon}=P_B[\vec{x}]_B$</p>
<p>$P_B^{-1}[\vec{x}]_{\epsilon}=[\vec{x}]_B$</p>
<p>对于其他非标准坐标系的转换只需要以标准坐标系为过渡即可</p>
<p>$[\vec{x}]_C=P_C^{-1}P_B[\vec{x}]_B$</p>
<p>$P_{B-&gt;C}=P_C^{-1}P_B,P_{C-&gt;B}=P_B^{-1}P_C$</p>
</blockquote>
<h2 id="线性变换"><a href="#线性变换" class="headerlink" title="线性变换"></a>线性变换</h2><blockquote>
<p>一个变换T(x)称为线性变换，必须满足</p>
<p>$T(u+v)=T(u)+T(v)\\T(cu)=cT(u)\ \ c\in R$</p>
<p>即对向量u+v做线性变换T，等价于对u,v分别做线性变换的和</p>
<p>对数倍的向量u做线性变换T，等价于对u做线性变换T后乘以倍数c</p>
</blockquote>
<blockquote>
<p>所有的矩阵都可以用来表示一个线性变换</p>
<p>用矩阵表示空间的视角和用矩阵表示变换的视角是等价的</p>
</blockquote>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><ul>
<li><p>不同维度空间的转换</p>
<p>3D空间转换到2D空间</p>
</li>
</ul>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200319211345.png" style="zoom:60%;" />

<pre><code>计算机视觉</code></pre><img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200319211450.png" style="zoom:67%;" />

<p>​        即通过2维图片判断三维空间的信息</p>
<ul>
<li>同维度空间转换的应用：压缩</li>
</ul>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200319211617.png" style="zoom:67%;" />

<p>​        通过转换该空间中的一组基，缩小数据信息量以压缩    </p>
<p>​        JPEG 就是通过这种转换坐标基的方法进行压缩</p>
<p>​        傅里叶变换和小波变换也都是这种思路，可以用于压缩。</p>
<h1 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h1><blockquote>
<p>行列式是 <strong>方阵</strong> 的一个属性</p>
</blockquote>
<blockquote>
<p>我们可以把行列式看做该方阵所构成单位空间的面积（二维）<br>$$<br>det\begin{pmatrix}a&amp;b\\c&amp;d\end{pmatrix}\ \ \begin{vmatrix}a&amp;b\\c&amp;d\end{vmatrix}<br>$$<br><code>det</code>就是行列式的标志，我们在二维空间中，可以看做是(a,b)和(c,d)两组基，那么该行列式就是求有(a,b)和(c,d)构成的平行四边形的面积</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200320223104.png" style="zoom:67%;" />

<blockquote>
<p>可以看到，该平行四边形的面积<br>$$<br>det\begin{pmatrix}a&amp;b\\c&amp;d\end{pmatrix}\ \<br>\begin{align}&amp;=(a+c)(b+d)-2bc-cd-ab\<br>&amp;=ab+cb+ad+cd-2bc-cd-ab\<br>&amp;=bc+ad-2bc\<br>&amp;=ad-bc<br>\end{align}<br>$$</p>
</blockquote>
<blockquote>
<p>行列式表示向量组在空间中形成的 <strong>有向</strong> 体积</p>
<p>在三维即以上的空间，体积的方向将变得极其复杂<br>$$<br>\begin{vmatrix}a&amp;b\\c&amp;d\end{vmatrix}=ad-bc\<br>\begin{vmatrix}c&amp;d\\a&amp;b\end{vmatrix}=bc-ad\<br>$$<br>简单说，在行列式中，向量排列的顺序是有意义的</p>
<p>交换两行，则行列式的值取反。</p>
</blockquote>
<h2 id="行列式的四大基本性质"><a href="#行列式的四大基本性质" class="headerlink" title="行列式的四大基本性质"></a>行列式的四大基本性质</h2><ul>
<li><p>$detI=1$</p>
</li>
<li><p>交换行列式的两行，则行列式的值取反</p>
</li>
<li><p>$\begin{vmatrix}ka&amp;kb\\c&amp;d\end{vmatrix}=k\begin{vmatrix}a&amp;b\\c&amp;d\end{vmatrix}$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200321104427.png" style="zoom:67%;" />

<blockquote>
<p> 如上图所示，我将（a,b）扩大k倍，做构成的平行四边形的面积也相应扩大k倍</p>
</blockquote>
</li>
<li><p>$\begin{vmatrix}a+a’&amp;b+b’\\c&amp;d\end{vmatrix}=\begin{vmatrix}a&amp;b\\c&amp;d\end{vmatrix}+\begin{vmatrix}a’&amp;b’\\c&amp;d\end{vmatrix}$</p>
<blockquote>
<p>这个我们可以继续通过二维空间构成平行四边形面积为例</p>
<p>不过，我们这里也可以直接计算就可以得到这样的结论<br>$$<br>\begin{vmatrix}a+a’&amp;b+b’\\c&amp;d\end{vmatrix}=(a+a’)d-c(b+b’)\<br>=ad-bc+a’d-b’c\<br>=\begin{vmatrix}a&amp;b\\c&amp;d\end{vmatrix}+\begin{vmatrix}a’&amp;b’\\c&amp;d\end{vmatrix}<br>$$</p>
</blockquote>
</li>
</ul>
<h2 id="行列式与矩阵的逆"><a href="#行列式与矩阵的逆" class="headerlink" title="行列式与矩阵的逆"></a>行列式与矩阵的逆</h2><blockquote>
<p>如果行列式的一行是其他行的线性组合，则行列式的值为0 &lt;=&gt;矩阵不可逆</p>
</blockquote>
<blockquote>
<p>首先我们来看前半段，行列式的一行是其他行的线性组合，则行列式的值为0<br>$$<br>\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\k_1a+k_2d&amp;k_1b+k_2e&amp;k_1c+k_2f\end{vmatrix}\<br>=\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\k_1a&amp;k_1b&amp;k_1c\end{vmatrix}+\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\k_2d&amp;k_2e&amp;k_2f\end{vmatrix}<br>$$<br>我们可以看到，拆分后的两个矩阵第三行都是第一行的特定倍数，而我们之前说过，行列式的每一行应当是所构成空间的一组基，而拆分后的矩阵必然是没有达到这个要求的。</p>
<p>我们就以三维空间来看，、拆分后的矩阵只得到了三维空间的一组基中的两个维度的方向，即只能构成一个面，得到的空间体积为0.所以拆分后的矩阵的行列式的值必然是0</p>
</blockquote>
<blockquote>
<p>我们再看，后半段，矩阵不可逆，我们之前就得到了如果矩阵的行向量存在线性相关，则矩阵不可逆。</p>
</blockquote>
<blockquote>
<p>因此我们得到这样的结论<br>$$<br>det(A)=0&lt;=&gt;A不可逆\<br>det(A)\neq0&lt;=&gt;A可逆<br>$$</p>
</blockquote>
<h2 id="计算行列式的值"><a href="#计算行列式的值" class="headerlink" title="计算行列式的值"></a>计算行列式的值</h2><blockquote>
<p>首先如果一个方阵加（减）另一行的k倍，行列式的值不变<br>$$<br>\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\g&amp;h&amp;i\end{vmatrix}=<br>\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\g-ka&amp;h-kb&amp;i-kc\end{vmatrix}\<br>=\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\g&amp;h&amp;i\end{vmatrix}-\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\ka&amp;kb&amp;kc\end{vmatrix}\<br>=\begin{vmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\g&amp;h&amp;i\end{vmatrix}-0<br>$$</p>
</blockquote>
<blockquote>
<p>所以一个方阵的行列式的值</p>
<p>就等于其进行高斯消元法后的结果（上三角矩阵U）</p>
<p>等于进行高斯约旦消元法后的结果（对角矩阵D）</p>
<p>不要归一化：行置换列置换变操作符号</p>
<p>如果消元结果有零行，行列式的值为0</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200321112913.png" style="zoom:80%;" />

<blockquote>
<p>因为一个上三角或者下三角矩阵必然可以化成一个对角矩阵的样子，所以我们得到一个上三角矩阵或下三角矩阵即可计算该行列式的值，不用做进一步操作。</p>
</blockquote>
<h2 id="初等矩阵与行列式"><a href="#初等矩阵与行列式" class="headerlink" title="初等矩阵与行列式"></a>初等矩阵与行列式</h2><blockquote>
<p>回忆：初等矩阵：对单位矩阵进行初等行操作</p>
<p>所以$det(A\cdot B)=det(E_k…E_2E_1B)$</p>
</blockquote>
<blockquote>
<p>那么我们就先研究初等矩阵的行列式</p>
<p>如果E是单位矩阵的某一行乘以k    $det(E)=k$</p>
<p>方阵EB是B中某一行乘以k</p>
<p>$det(E\cdot B)=kdet(B)\ \ det(E)\cdot det(B)=kdet(B)    $</p>
<p>如果E是单位矩阵的某两行交换    $det(E)=-1$</p>
<p>方阵EB是B中某两行交换</p>
<p>$det(E\cdot B)=-det(B)\ \ det(E)\cdot det(B)=-det(B)    $</p>
<p>如果E是单位矩阵的某行加（减）另一行的k倍 $det(E)=1$</p>
<p>方阵EB是B中的某行加（减）另一行的k倍</p>
<p>$det(E\cdot B)=det(B)\ \ det(E)\cdot det(B)=det(B)    $</p>
</blockquote>
<blockquote>
<p>所以$det(E\cdot B)=det(E)\cdot det(B)$</p>
</blockquote>
<blockquote>
<p>$det(A\cdot B)=det(E_K…E_2E_1B)=det(E_k)\cdot…\cdot det(E_2)\cdot det(E_1)\cdot det(B)$</p>
<p>$det(A)=det(E_K…E_2E_1I)=det(E_k)\cdot…\cdot det(E_2)\cdot det(E_1)\cdot det(I)$</p>
<p><strong>所以$det(A\cdot B)=det(A)\cdot det(B)$</strong></p>
</blockquote>
<blockquote>
<p>我们通过这个性质，又可以进一步得出</p>
<p>$det(I)=det(A)\cdot det(A^{-1})\\det(A)\cdot det(A^{-1})=1\\det(A^{-1})=\frac{1}{det(A)}$</p>
</blockquote>
<h2 id="行式就是列式"><a href="#行式就是列式" class="headerlink" title="行式就是列式"></a>行式就是列式</h2><blockquote>
<p>$det(A)=det(A^T)$</p>
</blockquote>
<blockquote>
<p>我们上面说过，任意A可以分解为PLUP’</p>
<p>$det(A)=det(PLUP’)=det(P)\cdot det(L)\cdot det(U)\cdot det(P’)$</p>
<p>$det(A^T)=det((PLUP’)^T)=det(P’^T)\cdot det(U^T)\cdot det(L^T)\cdot det(P^T)$</p>
<p>首先我们看L,U矩阵，很显然L,U转置后变成U,L，行列式的值不变</p>
<p>那么我们来看P，即一系列初等行变换矩阵相乘</p>
<p>如果E表示两行交换位置     $det(E)=det(E^T)$</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200321165419.png" style="zoom:70%;" />

<blockquote>
<p>我们可以发现，对E进行行变换后，    $det(E)=-1$，但是转置之后，又相当于又做了次行变换，再-1，即行变换矩阵的行列式等于该矩阵转置矩阵的行列式.</p>
<p>而列变换的矩阵也可以表示为多个行变换矩阵的乘积。</p>
<p>所以综上所述</p>
<p>$det(P’^T)\cdot det(U^T)\cdot det(L^T)\cdot det(P^T)=det(P)\cdot det(L)\cdot det(U)\cdot det(P’)$</p>
<p>即$det(A)=det(A^T)$</p>
</blockquote>
<blockquote>
<p>所以，我么之前讲的性质换成列一样存在<br>$$<br>\begin{vmatrix}ka&amp;b\\kc&amp;d\end{vmatrix}=k\begin{vmatrix}a&amp;b\\c&amp;d\end{vmatrix}\<br>\begin{vmatrix}a+a’&amp;b\\c+c’&amp;d\end{vmatrix}=\begin{vmatrix}a&amp;b\\c&amp;d\end{vmatrix}+\begin{vmatrix}a’&amp;b\\c’&amp;d\end{vmatrix}<br>$$<br>如果行列式的两列相同，则行列式的值为0</p>
<p>如果行列式的一列是其他列的线性组合，则行列式的值为0</p>
<p>如果一个方阵加（减）另一列的k倍，行列式的值不变</p>
</blockquote>
<h2 id="行列式的代数表达"><a href="#行列式的代数表达" class="headerlink" title="行列式的代数表达"></a>行列式的代数表达</h2><blockquote>
<p> 我们对于行列式更多的是对于行列式的性质的理解和应用，接下来的代数表达其实很少用到</p>
</blockquote>
<p>$$<br>\begin{vmatrix}a_{11}&amp;a_{12}&amp;…&amp;a_{1n}\\a_{21}&amp;a_{22}&amp;…&amp;a_{2n}\...&amp;…&amp;&amp;…\\a_{n1}&amp;a_{n2}&amp;…&amp;a_{nn}\end{vmatrix}=\sum_{i=1}^na_{1i}A_{1i}\<br>A_{1i}=(-1)^{i+1} M_{1i}\<br>其中M_{1i}是指原行列式删去a_{1i}所在行列后的行列式的值，我们叫做余子式，而A_{1i}称为代数余子式\<br>当然，并不是必须是第一行的a_{1n}，可以选取任意的某一行或者某一列做这样的求和计算\<br>但是，这样的计算量是非常大的，时间复杂度为O（n!）<br>$$</p>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200322180416.png" style="zoom:80%;" />

<blockquote>
<p>我们可以发现，这个计算就是我们常用的递归计算，所以在计算机中实现还是比较容易的，就是复杂度较高</p>
</blockquote>
<blockquote>
<p><strong>Cramer法则</strong></p>
<p>​    $A\vec{x}=\vec{b},x_i=\frac{\left|A_i(b)\right|}{\left|A\right|}$</p>
<p>其中$A_i(b)$是将A中的第i列换成b</p>
<p>具体推导这里不详细说明，只需做了解</p>
</blockquote>
<h1 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h1><p>$$<br>A=\begin{pmatrix}4&amp;-2\\1&amp;1\end{pmatrix}\<br>\begin{pmatrix}4&amp;-2\\1&amp;1\end{pmatrix}\begin{pmatrix}2\\2\end{pmatrix}=\begin{pmatrix}4\\4\end{pmatrix}\<br>\begin{pmatrix}4&amp;-2\\1&amp;1\end{pmatrix}\begin{pmatrix}2\\1\end{pmatrix}=\begin{pmatrix}6\\3\end{pmatrix}<br>$$</p>
<blockquote>
<p>我们可以发现A乘以这两个向量都相当于该向量乘以一个特定的数</p>
<p>即$A\vec{u}=\lambda\vec{u}$</p>
<p>我们称$\lambda$称为A的 <strong>特征值（eigenvalue）</strong></p>
<p>$\vec{u}$称为A对应于$\lambda$的 <strong>特征向量(eigenvector)</strong></p>
</blockquote>
<blockquote>
<p>求解特征值和特征向量$A\vec{u}=\lambda\vec{u}$</p>
<p>注意：零向量必然满足。是平凡解，所以，<strong>特征向量不考虑零向量</strong></p>
<p>但$\lambda=0$并不平凡，$A\vec{u}=0$</p>
<p>所以，<strong>特征值可以为0</strong></p>
</blockquote>
<p>$$<br>A\vec{u}=\lambda\vec{u}\<br>A\vec{u}-\lambda\vec{u}=0\<br>A\vec{u}-\lambda I\vec{u}=0\<br>(A-\lambda I)\vec{u}=0<br>$$</p>
<blockquote>
<p>I是单位向量，我们希望得到的方程有非零解。</p>
<p>回忆之前的知识，如果该方程有唯一零解，即等价于系数矩阵行列式的值不为0.</p>
<p>那么，我们要有非零解，即使得行列式的值为0，便可求得。</p>
<p>即$det(A-\lambda I)=0$</p>
</blockquote>
<p>$$<br>例：A=\begin{pmatrix}4&amp;-2\\1&amp;1\end{pmatrix}\<br>那么特征方程\ \ \left|A-\lambda I\right|=\begin{vmatrix}4-\lambda&amp;-2\\1&amp;1-\lambda\end{vmatrix}\<br>=(4-\lambda)(2-\lambda)+2\<br>=(\lambda-2)(\lambda-3)=0\<br>\lambda_1=2 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \lambda_2=3\<br>\begin{pmatrix}2&amp;-2\\1&amp;-1\end{pmatrix}\vec{u}=0\ \ \ \ \ \begin{pmatrix}1&amp;-2\\1&amp;-2\end{pmatrix}\vec{u}=0\<br>\begin{pmatrix}1&amp;-1\\0&amp;0\end{pmatrix}=0\ \ \ \ \ \ \ \ \begin{pmatrix}1&amp;-2\\0&amp;0\end{pmatrix}=0 \<br>\vec{u}=\begin{pmatrix}1\\1\end{pmatrix}s \ \ \ \ \ \ \ \ \ \ \ \ \ \vec{u}=\begin{pmatrix}2\\1\end{pmatrix}s<br>$$</p>
<blockquote>
<p>这样我们便得到了两组特征值以及特征值所对应的特征向量</p>
<p>对应每个特征值的特征向量都是有无数多个的，只需要满足一定的线性关系即可。</p>
<p>$A\vec{u}=\lambda\vec{u}\\Ak\vec{u}=\lambda k\vec{u}$</p>
<p>k是可以两边约去的，所以特征向量是无数个。</p>
</blockquote>
<blockquote>
<p>$(A-\lambda I)\vec{u}=0$</p>
<p>特征向量组成的$A-\lambda I$零空间，刨除零向量</p>
<p>$E_\lambda=\{O\}\cup\{\lambda的特征向量\}$</p>
<p>$E_\lambda$称为$\lambda$对应的<strong>特征空间</strong></p>
</blockquote>
<blockquote>
<p>特征值其实也分多种特征值</p>
<p>$det(A-\lambda I)=0$</p>
<p>如果得到$\lambda_1=2,\lambda_2=3$,称为<strong>简单特征值</strong></p>
<p>如果得到$\lambda_1=\lambda_2=3$,<strong>多重特征值</strong>，多少个特征值相等称为<strong>重数</strong></p>
<p>如果得到$\lambda_1=i,\lambda_2=-i$,则称为 <strong>复数特征值</strong></p>
</blockquote>
<h2 id="特征值和特征向量的性质"><a href="#特征值和特征向量的性质" class="headerlink" title="特征值和特征向量的性质"></a>特征值和特征向量的性质</h2><blockquote>
<p>若特征值$\lambda=0$</p>
<p>即$A\vec{u}=0$,那么我们要求改线性系统不仅有零解，则<strong>A不可逆</strong></p>
</blockquote>
<blockquote>
<p>对于对角矩阵<br>$$<br>\left|A\right|=\begin{vmatrix}d_1&amp;0&amp;…&amp;0\\0&amp;d_2&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;d_n\end{vmatrix}=d_1d_2…d_n\<br>\left|A-\lambda  I\right|=\begin{vmatrix}d_1-\lambda &amp;0&amp;…&amp;0\\0&amp;d_2-\lambda &amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;d_n-\lambda \end{vmatrix}=(d_1-\lambda )(d_2-\lambda )…(d_n-\lambda )\<br>\lambda_1=d_1,\lambda_2=d_2,…,\lambda_n=d_n<br>$$<br>即 <strong>对角矩阵的特征值是其对角线上的元素</strong></p>
<p>上三角和下三角矩阵与对角矩阵相同。</p>
</blockquote>
<blockquote>
<p>若$\lambda $是A的特征值，则$\lambda ^m$是$A^m$的特征值</p>
<p>这个很好证明，我们通过数学归纳法证明<br>$$<br>m=1成立\ \ A\vec{u}=\lambda\vec{u}\<br>假设m=k成立 \ \ A^k\vec{u}=\lambda^k\vec{u}\<br>\begin{align}当m=k+1时\ \ A^{k+1}\vec{u}&amp;=A\cdot A^k\vec{u}\&amp;=A\cdot\lambda^k\vec{u}\<br>&amp;=\lambda^kA\vec{u}\<br>&amp;=\lambda^k\lambda\vec{u}=\lambda^{k+1}\vec{u}<br>\end{align}<br>$$<br>特殊的</p>
<p>若$\lambda $是A的特征值，则$\lambda ^{-1}$是$A^{-1}$的特征值</p>
</blockquote>
<blockquote>
<p>如果矩阵A 含有两个不同的特征值，则他们对应的特征向量线性无关<br>$$<br>A\vec{u}=\lambda_1\vec{u}\ \ \ \ A\vec{v}=\lambda_2\vec{v}\<br>反证法：假设线性相关\<br>即\vec{u}=k\vec{v}\ \ k\neq0\ \ A\vec{u}=A(k\vec{v})=kA\vec{v}\<br>\lambda_1\vec{u}=k\lambda_2\vec{v}\<br>对于\vec{u}=k\vec{v}，等式左右两边同时乘以\lambda_1\<br>即\lambda_1\vec{u}=k\lambda_1\vec{v}\<br>k\lambda_2\vec{v}-k\lambda_1\vec{v}=0\ \ \ k(\lambda_2-\lambda_1)\vec{v}=0,显然矛盾<br>$$</p>
</blockquote>
<h2 id="不简单的特征值和特征向量"><a href="#不简单的特征值和特征向量" class="headerlink" title="不简单的特征值和特征向量"></a>不简单的特征值和特征向量</h2><blockquote>
<p>单位矩阵</p>
<p>$A=\begin{pmatrix}1&amp;0\\0&amp;1\end{pmatrix}$</p>
<p>$\left|A-\lambda  I\right|=\begin{vmatrix}1-\lambda&amp;0\\0&amp;1-\lambda\end{vmatrix}=0$</p>
<p>$\lambda_1=\lambda_2=1$</p>
<p>我们代入原式</p>
<p>$(A-\lambda I)\vec{u}=0$</p>
<p>$\begin{pmatrix}0&amp;0\\0&amp;0\end{pmatrix}\vec{u}=0$</p>
<p>即二维平面上所有向量都是特征向量</p>
<p>我们再找一个矩阵</p>
<p>$A=\begin{pmatrix}3&amp;1\\0&amp;3\end{pmatrix}$</p>
<p>$\lambda_1=\lambda_2=3$</p>
<p>$\begin{pmatrix}0&amp;1\\0&amp;0\end{pmatrix}\vec{u}=0$</p>
<p>$\vec{u}=s\begin{pmatrix}1\\0\end{pmatrix}$</p>
<p>2阶方阵对应的线性无关的特征向量只有1个</p>
</blockquote>
<blockquote>
<p>最根本的结论</p>
<p>如果矩阵A的某个特征值的重数=k， 则对应的特征空间的维度&lt;=k</p>
<p>我们又把特征值的重数叫做<strong>代数重数</strong>，特征空间的维度叫做<strong>几何重数</strong></p>
<p>即<strong>几何重数不大于代数重数</strong></p>
<p>具体证明比较复杂，就不证明了。</p>
</blockquote>
<h2 id="矩阵相似型"><a href="#矩阵相似型" class="headerlink" title="矩阵相似型"></a>矩阵相似型</h2><blockquote>
<p>*<em>如果矩阵A,B满足$A=P^{-1}BP$ 则称A和B相似。$B=PAP^{-1}$     *</em></p>
<p>本质其实是不同的视角观察相同的内容</p>
<p>P是一个坐标系，则A变换是在P坐标系下观察的B变换</p>
<p>我们等式左右两边各乘以一个P坐标系下的坐标$[\vec{x}]_P$</p>
<p>为了证明$A[\vec{x}]_P=P^{-1}BP[\vec{x}]_P$，我们分别做A,B变换</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200323111657.png" style="zoom:80%;" />

<blockquote>
<p>在P坐标系中，我们通过A变换，将$[\vec{x}]_P$转换为$A[\vec{x}]_P$</p>
<p>而B是在标准坐标系中的转换，所以我们先将$[\vec{x}]_P$转换为标准坐标系中的向量$P[\vec{x}]_P$</p>
<p>然后进行B转换，得到$BP[\vec{x}]_P$</p>
<p>在将转换完成的标准坐标系坐标转换到P坐标系中，$P^{-1}BP[\vec{x}]_P$</p>
<p>即A,B都是相同的变换，只是在不同的坐标系中的变换而已，所以我们称A,B相似</p>
</blockquote>
<blockquote>
<p>进一步我们可以发现，A和B的特征方程相同即特征值相同。<br>$$<br>det(A-\lambda I)=det(P^{-1}BP-\lambda I)=det(P^{-1}BP-\lambda P^{-1}P)\<br>=det(P^{-1}BP-P^{-1}\lambda P)=det(P^{-1}(B-\lambda I)P)\<br>=det(P^{-1})det(B-\lambda I)det(P)\<br>=det(B-\lambda I)det(P^{-1}P)\=det(B-\lambda I)<br>$$</p>
</blockquote>
<h2 id="矩阵对角化"><a href="#矩阵对角化" class="headerlink" title="矩阵对角化"></a>矩阵对角化</h2><blockquote>
<p>如果A有n个线性无关的特征向量，则A和某个D相似。$A=PDP^{-1}$</p>
<p>称A可以被对角化<br>$$<br>D=\begin{pmatrix}\lambda_1&amp;0&amp;…&amp;0\\0&amp;\lambda_2&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;\lambda_n\end{pmatrix},<br>P=\begin{pmatrix}|&amp;|&amp;&amp;|\\\vec{u_1}&amp;\vec{u_2}&amp;…&amp;\vec{u_n}\|&amp;|&amp;&amp;|\end{pmatrix}<br>$$<br>D中对角线上的元素为A的特征值，P中每一列为特征值对应的特征向量</p>
</blockquote>
<blockquote>
<p>为了证明，我们左右同时乘以一个$P^{-1}$<br>$$<br>AP=PD\<br>AP=A\begin{pmatrix}|&amp;|&amp;&amp;|\\\vec{u_1}&amp;\vec{u_2}&amp;…&amp;\vec{u_n}\|&amp;|&amp;&amp;|\end{pmatrix}=<br>\begin{pmatrix}|&amp;|&amp;&amp;|\\A\vec{u_1}&amp;A\vec{u_2}&amp;…&amp;A\vec{u_n}\|&amp;|&amp;&amp;|\end{pmatrix}=<br>\begin{pmatrix}|&amp;|&amp;&amp;|\\\lambda_1\vec{u_1}&amp;\lambda_2\vec{u_2}&amp;…&amp;\lambda_n\vec{u_n}\|&amp;|&amp;&amp;|\end{pmatrix}\<br>PD=\begin{pmatrix}|&amp;|&amp;&amp;|\\\vec{u_1}&amp;\vec{u_2}&amp;…&amp;\vec{u_n}\|&amp;|&amp;&amp;|\end{pmatrix}\begin{pmatrix}\lambda_1&amp;0&amp;…&amp;0\\0&amp;\lambda_2&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;\lambda_n\end{pmatrix}=\begin{pmatrix}|&amp;|&amp;&amp;|\\\lambda_1\vec{u_1}&amp;\lambda_2\vec{u_2}&amp;…&amp;\lambda_n\vec{u_n}\|&amp;|&amp;&amp;|\end{pmatrix}<br>$$<br>所以等式成立</p>
</blockquote>
<blockquote>
<p>注意：如果A没有n个不同的特征值，A不一定不能被对角化</p>
</blockquote>
<h2 id="矩阵对角化的应用"><a href="#矩阵对角化的应用" class="headerlink" title="矩阵对角化的应用"></a>矩阵对角化的应用</h2><blockquote>
<p>求解矩阵的幂</p>
<p>我们知道$A=PDP^{-1}$</p>
<p>那么$A^2=PDP^{-1}PDP^{-1}=PDIDP^{-1}=PD^2P^{-1}$</p>
<p>$A^3=PD^2P^{-1}PDP^{-1}=PD^2IDP^{-1}=PD^3P^{-1}$</p>
<p>…</p>
<p>$A^n=PD^nP^{-1}$</p>
</blockquote>
<blockquote>
<p>那么对于$D^n$怎么求解呢</p>
<p>$D=\begin{pmatrix}\lambda_1&amp;0&amp;…&amp;0\\0&amp;\lambda_2&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;\lambda_n\end{pmatrix},D^2=\begin{pmatrix}\lambda_1&amp;0&amp;…&amp;0\\0&amp;\lambda_2&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;\lambda_n\end{pmatrix}\begin{pmatrix}\lambda_1&amp;0&amp;…&amp;0\\0&amp;\lambda_2&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;\lambda_n\end{pmatrix}=\begin{pmatrix}\lambda_1^2&amp;0&amp;…&amp;0\\0&amp;\lambda_2^2&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;\lambda_n^2\end{pmatrix}$</p>
</blockquote>
<blockquote>
<p>即$A^n=PD^nP^{-1}=P\begin{pmatrix}\lambda_1^n&amp;0&amp;…&amp;0\\0&amp;\lambda_2^n&amp;…&amp;0\...&amp;…&amp;…&amp;…\\0&amp;0&amp;…&amp;\lambda_n^n\end{pmatrix}P^{-1}$</p>
</blockquote>
<blockquote>
<p>对于矩阵的幂有什么用呢？</p>
<p>因为大量问题的形式是：$\vec{u}_k=A^k\vec{u}_0$</p>
<p>这个公式表示的是一个动态系统</p>
<p>这个动态系统的状态是随着时间的变换在动态变化的，而变化则为A，$\vec{u}$则为状态向量</p>
<p>我初始的状态为$\vec{u_0}$,经过一次变换后，$\vec{u_1}=A\vec{u_0}$</p>
<p>经过k次变换后，$\vec{u}_k=A^k\vec{u}_0=PD^nP^{-1}\vec{u_0}$</p>
<p><strong>这里我们就可以发现，矩阵A的特征值其实就反应了系统的各个变量的变化速率</strong></p>
</blockquote>
<h2 id="完美的对称矩阵"><a href="#完美的对称矩阵" class="headerlink" title="完美的对称矩阵"></a>完美的对称矩阵</h2><blockquote>
<p>对称矩阵    $A=A^T$</p>
<p>为什么说对称矩阵是完美的呢？</p>
<p>对称矩阵的特征值一定是实数。</p>
<p>对称矩阵的多重特征值，其对应的特征空间的维度一定等于重数</p>
<p>对称矩阵的几何重数等于代数重数</p>
<p>对称矩阵一定有n个线性无关的特征向量</p>
<p>即对称矩阵一定可以被对角化</p>
<p>这些性质证明过于麻烦，只做了解即可。</p>
</blockquote>
<h2 id="正交对角化"><a href="#正交对角化" class="headerlink" title="正交对角化"></a>正交对角化</h2><blockquote>
<p> 对称矩阵的所有不同的特征值对应的特征向量相互垂直</p>
</blockquote>
<p>$$<br>假设矩阵A的两个特征向量v_1,v_2对应不同的特征值\lambda_1.\lambda_2\<br>证明：\vec{v_1}\cdot \vec{v_2}=0\<br>(\lambda_1\vec{v_1})\cdot \vec{v_2}=(\lambda_1\vec{v_1})^T\vec{v_2}\ \ 我们把(\lambda_1\vec{v_1})这个向量转为为(\lambda_1\vec{v_1})^T这个矩阵，所乘结果不变\<br>=(A\vec{v_1})^T\vec{v_2}=\vec{v_1}^TA^T\vec{v_2}=v_1^TA\vec{v_2},因为A时候对角矩阵，所以A=A^T\<br>=\vec{v_1}^T\lambda_2\vec{v_2}=(\lambda_2\vec{v_1}^T)\vec{v_2}=\lambda_2\vec{v_1}\cdot \vec{v_2}\<br>(\lambda_1-\lambda_2)(\vec{v_1}\cdot \vec{v_2})=0\<br>即得证\vec{v_1}\cdot \vec{v_2}=0<br>$$</p>
<blockquote>
<p>如果A是对称矩阵</p>
<p>$A=QDQ^{-1}$    将每一个特征向量标准化，Q即为标准特征向量</p>
<p>因为标准正交矩阵$Q^{-1}=Q^T$</p>
<p>所以$A=QDQ^{T}$，即正交对角化</p>
</blockquote>
<blockquote>
<p>那么，如果A可以被正交对角化，则A一定是对称矩阵</p>
<p>这个很好证明：<br>$$<br>\begin{align}A=QDQ^T,A^T&amp;=(QDQ^T)^T\<br>&amp;=(Q^T)^TD^TQ^T\<br>&amp;=QDQ^T=A<br>\end{align}<br>$$<br>所以 <strong>A是对称矩阵&lt;=&gt;A可以被正交对角化</strong></p>
</blockquote>
<h2 id="奇异值"><a href="#奇异值" class="headerlink" title="奇异值"></a>奇异值</h2><blockquote>
<p>我们上面介绍的特征值，特征向量以及正交对角化等等都是基于方阵来说，但是，显然还有很多非方阵的矩阵，那么之前讲的都的都白说了吗，必然不是。</p>
<p>我们给定任意一个矩阵A，<strong>若A是一个m<em>n的矩阵，则$A^TA$是一个 n\</em>n的方阵，且对称</strong></p>
<p>方阵很好理解，但是对称，我们这边稍微说明一下</p>
<p>$A^TA$    第i行j列元素：$A^T$第i行点乘A第j列，即A第i列点乘A第j列</p>
<p>​             第j行i列元素：$A^T$第j行点乘A第i列，即A第j列点乘A第i列</p>
<p>显示是相等的，所以$A^TA$也是一个对称矩阵</p>
</blockquote>
<blockquote>
<p>既然是对称矩阵，那么$A^TA$必然可以被正交对角化，拥有n个实数特征值；n个互相垂直的标准特征向量</p>
<p>记特征值为$\lambda_1,\lambda_2,…,\lambda_n$，标准特征向量 $\vec{v_1},\vec{v_2},…,\vec{v_n}$</p>
</blockquote>
<blockquote>
<p>$$<br>\parallel A\vec{v_i}\parallel^2=(A\vec{v_i})\cdot(A\vec{v_i})=(Av_i)^T\cdot(Av_i)=v_i^TA^TAv_i\=v_i^T(A^TAv_i)=v_i^T(\lambda_iv_i)\=\lambda_iv_i^Tv_i=\lambda_i\parallel \vec{v_i}\parallel^2=\lambda_i<br>$$</p>
<p>我们可以发现$\parallel A\vec{v_i}\parallel^2=\lambda_i&gt;=0$</p>
<p>我们定义$\sigma=\sqrt{\lambda_i}$为 <strong>奇异值（Singular Value）</strong></p>
</blockquote>
<blockquote>
<p>那么我们为什么要研究$A\vec{v_i}$ 呢？</p>
<p>因为$\{A\vec{v_i}\}$是A的列空间的一组正交基   $\lambda_i\neq0$<br>$$<br>首先，我们先来证明简单的正交性：(A\vec{v_i})\cdot(A\vec{v_j})=(Av_i)^T\cdot(Av_j)=v_i^TA^TAv_j\<br>=v_i^T(A^TAv_j)=v_i^T(\lambda_jv_j)\<br>=\lambda_jv_i^Tv_j=\lambda_j(\vec{v_i}\cdot\vec{v_j})=0,因为v_i,v_j正交<br>$$</p>
<p>$$<br>接下来我们再来证明\{A\vec{v_i}\}是A的列空间的一组基\<br>首先\{\vec{v_1},\vec{v_2},…,\vec{v_n}\}是n维空间的一组基\ \ \ \vec{x}=k_1\vec{v_1}+k_2\vec{v_2}+…+k_n\vec{v_n}\<br>那么对于A的列空间，我们可以把该空间的任意向量表示为\<br>\vec{y}=A\vec{x}=Ak_1\vec{v_1}+Ak_2\vec{v_2}+…+Ak_n\vec{v_n}\<br>因为矩阵A为m<em>n,而\vec{x}为n</em>1的向量，所以结果为m*1的向量\<br>我们假定{\vec{v_n}}中有r个特征值非零的向量，因为若特征值为零，则\parallel A\vec{v_i}\parallel=0，为零向量\<br>所以\vec{y}=k_1A\vec{v_1}+k_2A\vec{v_2}+…+k_rA\vec{v_r}+0…+0<br>$$</p>
</blockquote>
<blockquote>
<p>如果A有r个不为零的奇异值：$\{A\vec{v_1},A\vec{v_2},…,A\vec{v_r}\}$是A的列空间的一组正交基</p>
<p>A的列空间的维度为r；rank(A)=r</p>
<p>$\{\frac{A\vec{v_1}}{\sigma_1},\frac{A\vec{v_2}}{\sigma_2},…,\frac{A\vec{v_r}}{\sigma_r}\}$是A的列空间的一组标准正交基</p>
<p>$\{\vec{u_1},\vec{u_2},…,\vec{u_r}\}$是A的列空间的一组标准正交基,$\vec{u_i}=\frac{A\vec{v_r}}{\sigma_r}$</p>
</blockquote>
<h2 id="矩阵的SVD分解"><a href="#矩阵的SVD分解" class="headerlink" title="矩阵的SVD分解"></a>矩阵的SVD分解</h2><blockquote>
<p>矩阵的SVD分解 - Singular Value Decomposition，即矩阵的奇异值分解</p>
<p>SVD分解对任意形状的矩阵都适用</p>
</blockquote>
<blockquote>
<p>$A=U\sum V^T$，如果A是m*n的矩阵</p>
<p>U是m*m的矩阵；$\sum$是m*n的矩阵；V是n*n的矩阵</p>
<p>V是$A^TA$的特征向量矩阵进行标准化</p>
<p>$U=\begin{pmatrix}|&amp;|&amp;&amp;|\\\vec{u_1}&amp;\vec{u_2}&amp;…&amp;\vec{u_m}\|&amp;|&amp;&amp;|\end{pmatrix}$</p>
<p>前r个u $\vec{u_i}=\frac{A\vec{v_r}}{\sigma_r},\sigma_i\neq0$,后面的u使用Gram-Schmidt进行拓展</p>
<p>$\sum=\begin{pmatrix}\sigma_1&amp;&amp;&amp;&amp;\&amp;\sigma_2&amp;&amp;&amp;0\&amp;&amp;…&amp;&amp;\\0&amp;&amp;&amp;\sigma_r&amp;\&amp;0&amp;&amp;&amp;0\end{pmatrix}=\begin{pmatrix}D&amp;0\\0&amp;0\end{pmatrix}$</p>
</blockquote>
<blockquote>
<p>那么我接下里进行证明<br>$$<br>证明：AV=U\sum,v_i是A^TA的标准特征向量\<br>AV=A\begin{pmatrix}|&amp;|&amp;&amp;|\\\vec{v_1}&amp;\vec{v_2}&amp;…&amp;\vec{v_n}\|&amp;|&amp;&amp;|\end{pmatrix}=\begin{pmatrix}|&amp;|&amp;&amp;|\\A\vec{v_1}&amp;A\vec{v_2}&amp;…&amp;A\vec{v_n}\|&amp;|&amp;&amp;|\end{pmatrix}\<br>=\begin{pmatrix}|&amp;&amp;|&amp;&amp;\\\sigma_1\vec{u_1}&amp;…&amp;\sigma_r\vec{u_r}&amp;0&amp;…&amp;0\|&amp;&amp;|&amp;&amp;\end{pmatrix}<br>$$</p>
<p>$$<br>U\sum=\begin{pmatrix}|&amp;|&amp;&amp;|\\\vec{u_1}&amp;\vec{u_2}&amp;…&amp;\vec{u_m}\|&amp;|&amp;&amp;|\end{pmatrix}\begin{pmatrix}\sigma_1&amp;&amp;&amp;&amp;\&amp;\sigma_2&amp;&amp;&amp;0\&amp;&amp;…&amp;&amp;\\0&amp;&amp;&amp;\sigma_r&amp;\&amp;0&amp;&amp;&amp;0\end{pmatrix}\<br>=\begin{pmatrix}|&amp;&amp;|&amp;&amp;\\\sigma_1\vec{u_1}&amp;…&amp;\sigma_r\vec{u_r}&amp;0&amp;…&amp;0\|&amp;&amp;|&amp;&amp;\end{pmatrix}\<br>显然等式两边相等，得证<br>$$</p>
</blockquote>
<blockquote>
<p>那么我们如何进行矩阵的SVD分解呢</p>
<p>首先我们求解$A^TA$的特征值和特征向量</p>
<p>非零特征值开根号（奇异值）得到m*n的∑，奇异值从大到小排序</p>
<p>特征向量标准化后得到m*n的V</p>
<p>$\vec{u_i}=\frac{A\vec{v_r}}{\sigma_r}$，经过Gram-Schmidt扩展得到m*m的U</p>
</blockquote>
<h2 id="SVD分解的应用"><a href="#SVD分解的应用" class="headerlink" title="SVD分解的应用"></a>SVD分解的应用</h2><blockquote>
<p>$A=U\sum V^T$ </p>
<p>如果A是m*n的矩阵，A是对一个n维向量做变换</p>
<p>V是n维空间的一个标准正交基</p>
<p>那么我们n维空间的任意一个向量都可以表示为</p>
<p>$\vec{x}=k_1\vec{v_1}+k_2\vec{v_2}+…+k_n\vec{v_n}=V\vec{k}$</p>
<p>那么我们对x进行变换</p>
<p>$A\vec{x}=U\sum V^T\vec{x}=U\sum V^TV\vec{k}=U\sum \vec{k}=U\begin{pmatrix}\sigma_1k_1\...\\\sigma_rk_r\\0\end{pmatrix}$</p>
<p>简单来说就是将V空间的向量x原本的坐标为$(k_1,k_2,…,k_n)$</p>
<p>做A变换其实就是U这个空间中对每一个坐标相应拉伸奇异值倍数</p>
<p>下图就是该应用的一个例子</p>
<p>原本一个圆，我们进行A变换后，在U空间上拉伸奇异值倍数后的图形</p>
</blockquote>
<img src="https://typora-cwh.oss-cn-hangzhou.aliyuncs.com/typora/20200324135225.png" style="zoom:80%;" />

<blockquote>
<p>$$<br>A=U\sum V^T=\begin{pmatrix}|&amp;|&amp;&amp;|\\\vec{u_1}&amp;\vec{u_2}&amp;…&amp;\vec{u_m}\|&amp;|&amp;&amp;|\end{pmatrix}\begin{pmatrix}\sigma_1&amp;&amp;&amp;&amp;\&amp;\sigma_2&amp;&amp;&amp;0\&amp;&amp;…&amp;&amp;\\0&amp;&amp;&amp;\sigma_r&amp;\&amp;0&amp;&amp;&amp;0\end{pmatrix}<br>\begin{pmatrix}-&amp;\vec{v_1}&amp;-\-&amp;\vec{v_2}&amp;-\&amp;…&amp;\-&amp;\vec{v_n}&amp;-\\\end{pmatrix}\<br>=\begin{pmatrix}|&amp;&amp;|&amp;&amp;\\\sigma_1\vec{u_1}&amp;…&amp;\sigma_r\vec{u_r}&amp;0&amp;…&amp;0\|&amp;&amp;|&amp;&amp;\end{pmatrix}\begin{pmatrix}-&amp;\vec{v_1}&amp;-\-&amp;\vec{v_2}&amp;-\&amp;…&amp;\-&amp;\vec{v_n}&amp;-\\\end{pmatrix}=\sigma_1u_1v_1^T+\sigma_2u_2v_2^T+…+\sigma_ru_rv_r^T<br>$$</p>
<p>那么我们就可以得到$A=U\sum V^T=\sigma_1u_1v_1^T+\sigma_2u_2v_2^T+…+\sigma_ru_rv_r^T$</p>
<p>因为我们之前对于奇异值是按由大到小拍序的，所以越往后的项值就越小。</p>
<p>那么我们就可以去除后面的比较小的项，进行压缩，去噪，降维等操作</p>
</blockquote>
<hr>
<blockquote>
<p>终于把这个写完了，但是总体来说，只是大概的一个目录，具体的证明和计算都没有怎么给出。</p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" rel="tag"># 线性代数</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/09/Markdown-%E7%9B%B8%E5%85%B3%E8%AF%AD%E6%B3%95/" rel="prev" title="Markdown常用操作">
      <i class="fa fa-chevron-left"></i> Markdown常用操作
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/06/15/SpringBoot%E5%88%9D%E8%AF%86/" rel="next" title="SpringBoot初识">
      SpringBoot初识 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#概论"><span class="nav-number">1.</span> <span class="nav-text">概论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#向量"><span class="nav-number">2.</span> <span class="nav-text">向量</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#行向量和列向量"><span class="nav-number">2.1.</span> <span class="nav-text">行向量和列向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量加法"><span class="nav-number">2.2.</span> <span class="nav-text">向量加法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量数量乘法"><span class="nav-number">2.3.</span> <span class="nav-text">向量数量乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量运算的基本性质"><span class="nav-number">2.4.</span> <span class="nav-text">向量运算的基本性质</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#零向量"><span class="nav-number">2.5.</span> <span class="nav-text">零向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量的长度"><span class="nav-number">2.6.</span> <span class="nav-text">向量的长度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#单位向量"><span class="nav-number">2.7.</span> <span class="nav-text">单位向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量的点乘"><span class="nav-number">2.8.</span> <span class="nav-text">向量的点乘</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向量的点乘的应用"><span class="nav-number">2.9.</span> <span class="nav-text">向量的点乘的应用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#矩阵"><span class="nav-number">3.</span> <span class="nav-text">矩阵</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是矩阵"><span class="nav-number">3.1.</span> <span class="nav-text">什么是矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵基本运算"><span class="nav-number">3.2.</span> <span class="nav-text">矩阵基本运算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵看做系统"><span class="nav-number">3.3.</span> <span class="nav-text">矩阵看做系统</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵和矩阵的乘法"><span class="nav-number">3.4.</span> <span class="nav-text">矩阵和矩阵的乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的转置"><span class="nav-number">3.5.</span> <span class="nav-text">矩阵的转置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#更多的变换矩阵"><span class="nav-number">3.6.</span> <span class="nav-text">更多的变换矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#单位矩阵"><span class="nav-number">3.7.</span> <span class="nav-text">单位矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的逆"><span class="nav-number">3.8.</span> <span class="nav-text">矩阵的逆</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#用矩阵表示空间"><span class="nav-number">3.9.</span> <span class="nav-text">用矩阵表示空间</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性系统"><span class="nav-number">4.</span> <span class="nav-text">线性系统</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#高斯消元法"><span class="nav-number">4.1.</span> <span class="nav-text">高斯消元法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高斯约旦消元法"><span class="nav-number">4.2.</span> <span class="nav-text">高斯约旦消元法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#行最简形式"><span class="nav-number">4.3.</span> <span class="nav-text">行最简形式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#齐次线性方程组"><span class="nav-number">4.4.</span> <span class="nav-text">齐次线性方程组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#求解矩阵的逆"><span class="nav-number">4.5.</span> <span class="nav-text">求解矩阵的逆</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#初等矩阵"><span class="nav-number">4.6.</span> <span class="nav-text">初等矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#初等矩阵和可逆性"><span class="nav-number">4.7.</span> <span class="nav-text">初等矩阵和可逆性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#为什么矩阵的逆那么重要？"><span class="nav-number">4.8.</span> <span class="nav-text">为什么矩阵的逆那么重要？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的LU分解"><span class="nav-number">4.9.</span> <span class="nav-text">矩阵的LU分解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PLU分解"><span class="nav-number">4.10.</span> <span class="nav-text">PLU分解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#列交换"><span class="nav-number">4.11.</span> <span class="nav-text">列交换</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性组合"><span class="nav-number">5.</span> <span class="nav-text">线性组合</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性相关与线性无关"><span class="nav-number">5.1.</span> <span class="nav-text">线性相关与线性无关</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生成空间"><span class="nav-number">5.2.</span> <span class="nav-text">生成空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#空间的基"><span class="nav-number">5.3.</span> <span class="nav-text">空间的基</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#空间"><span class="nav-number">6.</span> <span class="nav-text">空间</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#广义向量空间"><span class="nav-number">6.1.</span> <span class="nav-text">广义向量空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#子空间"><span class="nav-number">6.2.</span> <span class="nav-text">子空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#维度"><span class="nav-number">6.3.</span> <span class="nav-text">维度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#行空间"><span class="nav-number">6.4.</span> <span class="nav-text">行空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#列空间"><span class="nav-number">6.5.</span> <span class="nav-text">列空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的秩和矩阵的逆"><span class="nav-number">6.6.</span> <span class="nav-text">矩阵的秩和矩阵的逆</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#零空间"><span class="nav-number">6.7.</span> <span class="nav-text">零空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#左零空间"><span class="nav-number">6.8.</span> <span class="nav-text">左零空间</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正交"><span class="nav-number">7.</span> <span class="nav-text">正交</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#正交基和标准正交基"><span class="nav-number">7.1.</span> <span class="nav-text">正交基和标准正交基</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一维投影"><span class="nav-number">7.2.</span> <span class="nav-text">一维投影</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高维投影和Gram-Schmidt过程"><span class="nav-number">7.3.</span> <span class="nav-text">高维投影和Gram Schmidt过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#标准正交基的性质"><span class="nav-number">7.4.</span> <span class="nav-text">标准正交基的性质</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的QR分解"><span class="nav-number">7.5.</span> <span class="nav-text">矩阵的QR分解</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#坐标系"><span class="nav-number">8.</span> <span class="nav-text">坐标系</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#坐标系转换"><span class="nav-number">8.1.</span> <span class="nav-text">坐标系转换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性变换"><span class="nav-number">8.2.</span> <span class="nav-text">线性变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#应用"><span class="nav-number">8.3.</span> <span class="nav-text">应用</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#行列式"><span class="nav-number">9.</span> <span class="nav-text">行列式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#行列式的四大基本性质"><span class="nav-number">9.1.</span> <span class="nav-text">行列式的四大基本性质</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#行列式与矩阵的逆"><span class="nav-number">9.2.</span> <span class="nav-text">行列式与矩阵的逆</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#计算行列式的值"><span class="nav-number">9.3.</span> <span class="nav-text">计算行列式的值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#初等矩阵与行列式"><span class="nav-number">9.4.</span> <span class="nav-text">初等矩阵与行列式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#行式就是列式"><span class="nav-number">9.5.</span> <span class="nav-text">行式就是列式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#行列式的代数表达"><span class="nav-number">9.6.</span> <span class="nav-text">行列式的代数表达</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#特征值和特征向量"><span class="nav-number">10.</span> <span class="nav-text">特征值和特征向量</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#特征值和特征向量的性质"><span class="nav-number">10.1.</span> <span class="nav-text">特征值和特征向量的性质</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#不简单的特征值和特征向量"><span class="nav-number">10.2.</span> <span class="nav-text">不简单的特征值和特征向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵相似型"><span class="nav-number">10.3.</span> <span class="nav-text">矩阵相似型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵对角化"><span class="nav-number">10.4.</span> <span class="nav-text">矩阵对角化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵对角化的应用"><span class="nav-number">10.5.</span> <span class="nav-text">矩阵对角化的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#完美的对称矩阵"><span class="nav-number">10.6.</span> <span class="nav-text">完美的对称矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正交对角化"><span class="nav-number">10.7.</span> <span class="nav-text">正交对角化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#奇异值"><span class="nav-number">10.8.</span> <span class="nav-text">奇异值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵的SVD分解"><span class="nav-number">10.9.</span> <span class="nav-text">矩阵的SVD分解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SVD分解的应用"><span class="nav-number">10.10.</span> <span class="nav-text">SVD分解的应用</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Wanghui Cai"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Wanghui Cai</p>
  <div class="site-description" itemprop="description">一些零零散散的学习总结</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/bigmoom" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;bigmoom" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:15850180970@163.com" title="E-Mail → mailto:15850180970@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="beian"><a href="https://beian.miit.gov.cn/#/Integrated/index" rel="noopener" target="_blank">苏ICP备20010524 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wanghui Cai</span>
</div>




        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    

  

</body>
</html>
